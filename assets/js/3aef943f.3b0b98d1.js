"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[3150],{400:a=>{a.exports=JSON.parse('{"label":"playbook","permalink":"/Data-Platform-Playbook/tags/playbook","allTagsPath":"/Data-Platform-Playbook/tags","count":55,"items":[{"id":"playbook/querying-and-analysing-data/time-series-analysis/introduction","title":"1. Introduction to Time Series Helpers","description":"Introduction to Time Series Helpers","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/introduction"},{"id":"playbook/querying-and-analysing-data/time-series-analysis/basic_helpers","title":"2. Basic Time Series helpers","description":"Generally useful Time Series Helpers","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/basic_helpers"},{"id":"playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example","title":"3. Step by Step Guide to Forecasting","description":"Step by Step Guide with examples to follow along with","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example"},{"id":"docs/alloy-ingestion","title":"Alloy data ingestion","description":"Description of the ingestion and refinement pipeline for Alloy Environmental Services data","permalink":"/Data-Platform-Playbook/docs/alloy-ingestion"},{"id":"docs/auto-adjusting-aws-budget","title":"Auto-adjusting AWS Budget Alerts","description":"Overview of the Auto-adjusting Budget Alerts","permalink":"/Data-Platform-Playbook/docs/auto-adjusting-aws-budget"},{"id":"docs/backdated-liberator-ingestion","title":"Backdated Liberator data ingestion","description":"Description of the backdated ingestion process for Liberator data","permalink":"/Data-Platform-Playbook/docs/backdated-liberator-ingestion"},{"id":"docs/CD-process","title":"CD Process","description":"Explaination of the CD process for the Data Platform","permalink":"/Data-Platform-Playbook/docs/CD-process"},{"id":"docs/CI-process","title":"CI Process","description":"Explaination of the CI process for the Data Platform","permalink":"/Data-Platform-Playbook/docs/CI-process"},{"id":"playbook/getting-access-to-data/Tableau-to-redshift","title":"Connecting to the Data Platform from Tableau","description":"How to connect to the Data Platform from Tableau Online using Redshift or Athena","permalink":"/Data-Platform-Playbook/playbook/getting-access-to-data/Tableau-to-redshift"},{"id":"playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio","title":"Connecting to the Redshift cluster from Google Data Studio","description":"Connect to the Redshift cluster from Google Data Studio","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio"},{"id":"playbook/querying-and-analysing-data/create_a_data_extract_in_GDS","title":"Create a data extract in Google Data Studio","description":"Create an extract to optimise dashboard performance","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/create_a_data_extract_in_GDS"},{"id":"playbook/elements-of-the-platform/data-catalogue","title":"Data Catalogue","description":"What is a data catalogue?","permalink":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-catalogue"},{"id":"playbook/elements-of-the-platform/data-lake","title":"Data Lake","description":"This is an overview of the data lake, its responsibilities and how data moves through the zones within the data lake","permalink":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-lake"},{"id":"playbook/elements-of-the-platform/data-warehouse","title":"Data Warehouse","description":"This is an overview of the data warehouse, its responsibilities and how data is served from within the Data Platform","permalink":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-warehouse"},{"id":"playbook/transforming-data/using-aws-glue/deploy-glue-jobs","title":"Deploying Glue jobs to the Data Platform","description":"Creating Glue jobs in terraform","permalink":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs"},{"id":"playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets","title":"Exponential Smoothing ETS","description":"Forecast using Exponential Smoothing","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets"},{"id":"docs/exporting-snapshot-to-landing-zone","title":"Exporting database snapshots to the Data Platform Landing Zone","description":"Overview of how db snapshots are exported to the Data Platform Landing Zone","permalink":"/Data-Platform-Playbook/docs/exporting-snapshot-to-landing-zone"},{"id":"playbook/transforming-data/geospatial-enrichments","title":"Geospatial enrichment","description":"How to perform geospatial enrichment on data held in the data platform","permalink":"/Data-Platform-Playbook/playbook/transforming-data/geospatial-enrichments"},{"id":"playbook/getting-set-up/local-pyspark-environment","title":"Getting started with the local PySpark environment","description":"Setting up a PySpark environment on a local machine and running Data Platform scripts.","permalink":"/Data-Platform-Playbook/playbook/getting-set-up/local-pyspark-environment"},{"id":"glossary","title":"Glossary","description":"A Table of terms of Terms and Tools used by the Data Platform","permalink":"/Data-Platform-Playbook/glossary"},{"id":"playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide","title":"Guide to testing data quality in Glue Jobs","description":"A guide to continuous data quality testing in Glue Jobs","permalink":"/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide"},{"id":"playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide","title":"Guide to unit testing on the Data Platform","description":"A beginners guide to testing on the data platform","permalink":"/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide"},{"id":"playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets","title":"Holt Winters ETS","description":"Forecast using Holt Winters ETS","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets"},{"id":"archived-articles/import-files-from-google-to-S3","title":"Import files from google to s3","description":"Import files from google to s3 description","permalink":"/Data-Platform-Playbook/archived-articles/import-files-from-google-to-S3"},{"id":"docs/import-spreadsheet-from-g-drive","title":"Import spreadsheets from G Drive","description":"Overview of how data is imported from spreadsheets that are stored in G drive","permalink":"/Data-Platform-Playbook/docs/import-spreadsheet-from-g-drive"},{"id":"docs/import-external-files-to-landing-zone","title":"Importing external files to the Data Platform Landing Zone","description":"Overview of how files from external suppliers are imported to the Data Platform Landing Zone","permalink":"/Data-Platform-Playbook/docs/import-external-files-to-landing-zone"},{"id":"playbook/ingesting-data/manual-ingest-of-csv-files","title":"Ingest manually uploaded csv files","description":"Ingest data from csv files","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/manual-ingest-of-csv-files"},{"id":"playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive","title":"Ingest spreadsheet files from G Drive","description":"Ingest spreadsheet files from G Drive description","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive"},{"id":"docs/academy-ingestion","title":"Ingesting Academy data onto the Data Platform","description":"Overview of how Academy data is ingested onto the Data Platform from MS SQL databases and distributed to Housing Benefits & Needs and Revenues Departments","permalink":"/Data-Platform-Playbook/docs/academy-ingestion"},{"id":"playbook/ingesting-data/ingesting-api-data","title":"Ingesting data from an API to the Data Platform","description":"Ingesting API data into the Data Platform using an AWS Lambda function","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-api-data"},{"id":"playbook/ingesting-data/database-ingestion","title":"Ingesting data from databases into the Data Platform","description":"Ingesting database tables into the Data Platform using a JDBC Connection","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/database-ingestion"},{"id":"playbook/ingesting-data/google-sheets-import","title":"Ingesting data from Google Sheets","description":"Objective","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/google-sheets-import"},{"id":"playbook/ingesting-data/ingesting-dynamo-db-tables","title":"Ingesting Dynamo DB tables into the Landing Zone","description":"Ingesting tables from a Dynamo DB instance into the Data Platform landing zone","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-dynamo-db-tables"},{"id":"playbook/ingesting-data/event-streaming","title":"Ingesting new data entities via event streaming","description":"Setting up a new Kafka topic to streaming events to from a new data entity","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/event-streaming"},{"id":"playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone","title":"Ingesting RDS snapshot into the Data Platform Landing Zone","description":"Ingesting a snapshot of an RDS instance into the DataPlatform landing zone","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone"},{"id":"docs/liberator-ingestion","title":"Liberator data ingestion","description":"Description of the ingestion process for Liberator data","permalink":"/Data-Platform-Playbook/docs/liberator-ingestion"},{"id":"playbook/getting-set-up/notebook-setup","title":"Local Notebook Environment Setup","description":"Local Notebook Environment Setup","permalink":"/Data-Platform-Playbook/playbook/getting-set-up/notebook-setup"},{"id":"playbook/getting-set-up/onboarding-new-departments-to-the-platform","title":"Onboarding new departments to the platform","description":"How to add a new Google group for a department.","permalink":"/Data-Platform-Playbook/playbook/getting-set-up/onboarding-new-departments-to-the-platform"},{"id":"playbook/getting-set-up/onboarding-new-users-to-the-platform","title":"Onboarding new users to the platform","description":"How to add users to a Google group","permalink":"/Data-Platform-Playbook/playbook/getting-set-up/onboarding-new-users-to-the-platform"},{"id":"playbook/transforming-data/using-aws-glue/optimizing-glue-jobs","title":"Optimizing Glue jobs","description":"Elements for optimizing glue jobs","permalink":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs"},{"id":"playbook/ingesting-data/production-to-pre-production-sync","title":"Production to pre-production data sync","description":"Overview of how data is copied from production to pre-production","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/production-to-pre-production-sync"},{"id":"playbook/transforming-data/using-aws-glue/using-sagemaker","title":"Prototyping glue jobs in a notebook","description":"Prototyping transformation scripts using a Jupyter Notebook","permalink":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker"},{"id":"playbook/querying-and-analysing-data/querying-data-using-sql","title":"Querying the Data Platform using SQL within AWS Athena","description":"AWS Athena to query data in S3","permalink":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/querying-data-using-sql"},{"id":"docs/redshift","title":"Redshift - Creating users, databases and exposing data from Glue","description":"","permalink":"/Data-Platform-Playbook/docs/redshift"},{"id":"docs/ringgo-ingestion","title":"RingGo data ingestion","description":"Description of the ingestion process for RingGo data","permalink":"/Data-Platform-Playbook/docs/ringgo-ingestion"},{"id":"roles","title":"Roles","description":"There are currently four tiers of role within the data platform project, and they are as follows:","permalink":"/Data-Platform-Playbook/roles"},{"id":"playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs","title":"Scheduling Liberator Glue Jobs","description":"Schedule a glue job to run when new liberator data is added into the platform","permalink":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs"},{"id":"docs/tascomi-ingestion","title":"Tascomi data ingestion","description":"Description of the ingestion and refinement pipeline for Tascomi planning data","permalink":"/Data-Platform-Playbook/docs/tascomi-ingestion"},{"id":"playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script","title":"Tips on writing an API Ingestion script for AWS Lambda","description":"Recommendations to write an API ingestion script for a Lambda in the Data Platform","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script"},{"id":"playbook/ingesting-data/what-data-are-we-ingesting","title":"Types of data and ingestion process","description":"Due to the variety of data sources we have had to develop several different ingestion methods. These methods and the data being ingested are detailed in this section","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/what-data-are-we-ingesting"},{"id":"playbook/getting-set-up/using-github","title":"Using GitHub","description":"A guide on how to carry out common tasks in GitHub","permalink":"/Data-Platform-Playbook/playbook/getting-set-up/using-github"},{"id":"playbook/transforming-data/using-aws-glue/using-glue-studio","title":"Using Glue Studio","description":"Using AWS Glue Studio to create ETL processes.","permalink":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio"},{"id":"playbook/finding-data/data-catalogue","title":"Using the data catalogue","description":"How to use the data catalogue","permalink":"/Data-Platform-Playbook/playbook/finding-data/data-catalogue"},{"id":"playbook/ingesting-data/using-watermarks-to-record-job-states","title":"Using Watermarks to Record AWS GLue Job States Between Runs","description":"Use of the watermarks class for recording Glue job states between runs","permalink":"/Data-Platform-Playbook/playbook/ingesting-data/using-watermarks-to-record-job-states"},{"id":"docs/vpc-peering-connection-dataplatform-and-production-apis-account","title":"VPC Peering Connection between Data Platform and Production APIs AWS accounts","description":"Overview of how the VPC Peering Connection and its purpose","permalink":"/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account"}]}')}}]);