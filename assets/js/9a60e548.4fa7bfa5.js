"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[8313],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return c}});var o=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,o)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,o,n=function(e,t){if(null==e)return{};var a,o,n={},r=Object.keys(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=o.createContext({}),u=function(e){var t=o.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=u(e.components);return o.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var a=e.components,n=e.mdxType,r=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=u(a),c=n,h=m["".concat(s,".").concat(c)]||m[c]||d[c]||r;return a?o.createElement(h,i(i({ref:t},p),{},{components:a})):o.createElement(h,i({ref:t},p))}));function c(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=a.length,i=new Array(r);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,i[1]=l;for(var u=2;u<r;u++)i[u]=a[u];return o.createElement.apply(null,i)}return o.createElement.apply(null,a)}m.displayName="MDXCreateElement"},4910:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return p},default:function(){return m}});var o=a(7462),n=a(3366),r=(a(7294),a(3905)),i=["components"],l={title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",layout:"playbook_js",tags:["training"]},s="Module 2 - Transforming data & writing to the refined zone",u={unversionedId:"training-modules/module-2",id:"training-modules/module-2",isDocsHomePage:!1,title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",source:"@site/docs/training-modules/module-2.md",sourceDirName:"training-modules",slug:"/training-modules/module-2",permalink:"/Data-Platform-Playbook/training-modules/module-2",editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/training-modules/module-2.md",tags:[{label:"training",permalink:"/Data-Platform-Playbook/tags/training"}],version:"current",frontMatter:{title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",layout:"playbook_js",tags:["training"]},sidebar:"docs",previous:{title:"Module 1 - Ingesting data from Google Sheets",permalink:"/Data-Platform-Playbook/training-modules/module-1"},next:{title:"Ingesting Academy data onto the Data Platform",permalink:"/Data-Platform-Playbook/docs/academy-ingestion"}},p=[{value:"Overview",id:"overview",children:[]},{value:"Prerequisites",id:"prerequisites",children:[]},{value:"Step-by-step instructions",id:"step-by-step-instructions",children:[{value:"1. Developing the job script in a Jupyter notebook",id:"1-developing-the-job-script-in-a-jupyter-notebook",children:[]},{value:"2. Testing the finished job in AWS glue",id:"2-testing-the-finished-job-in-aws-glue",children:[]}]}],d={toc:p};function m(e){var t=e.components,l=(0,n.Z)(e,i);return(0,r.kt)("wrapper",(0,o.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"module-2---transforming-data--writing-to-the-refined-zone"},"Module 2 - Transforming data & writing to the refined zone"),(0,r.kt)("p",null,"In this module you will manipulate the data that you loaded into the Data Platform raw zone in ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1"},"module 1"),".\nYou will save the result of your work into the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/glossary#refined-zone"},"refined zone")," of the data platform.\nThe refined zone is for data that has been enhanced or enriched and is \u2018ready\u2019 for analysis.\nYou will be using ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/api/python/"},"PySpark")," to code your job, and ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/glue/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc"},"AWS Glue")," to run it. You will create your code in a Jupyter Notebook environment running in AWS Sagemaker before copying it to the AWS console.\nJupyter notebooks are a convenient way to test code locally as Glue Studio is not so straightforward for code development (despite what the name implies!). You can read more about Jupyter notebooks ",(0,r.kt)("a",{parentName:"p",href:"https://jupyter.org/"},"here"),"."),(0,r.kt)("p",null,"This module is all about prototyping within a sandbox environment and therefore we won\u2019t be pushing any code to the Data Platform GitHub repository."),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,"You\u2019ll write a few lines of code in PySpark which will include reading data from S3, joining the two Covid datasets together and then writing the newly created dataset back to S3 in the refined zone. Then, you will be working in the console, running your job and checking your data like in Module 1. "),(0,r.kt)("p",null,"PySpark is an interface that uses the Python programming language to access the Apache Spark cluster-computing framework; therefore the syntax will seem a bit different if you have used Python packages such as Pandas or NumPy before."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Please ensure that both ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-0"},"module 0")," and ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1"},"module 1")," is completed before proceeding."),(0,r.kt)("h2",{id:"step-by-step-instructions"},"Step-by-step instructions"),(0,r.kt)("h3",{id:"1-developing-the-job-script-in-a-jupyter-notebook"},"1. Developing the job script in a Jupyter notebook"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Launch the sandbox notebook following ",(0,r.kt)("a",{parentName:"li",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker"},"this guide"),"."),(0,r.kt)("li",{parentName:"ol"},'Open the notebook template called "using-pyspark.ipynb".',(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Familiarise yourself with the steps (variables, reading, transforming and writing data)."),(0,r.kt)("li",{parentName:"ul"},"Duplicate the template, saving it in the sandbox folder, and rename it."))),(0,r.kt)("li",{parentName:"ol"},"Prototype your own ETL job to transform the data in PySpark. The ",(0,r.kt)("a",{parentName:"li",href:"https://sparkbyexamples.com/pyspark-tutorial/"},"PySpark By Examples website")," is a handy resource to write your code. Please try the following things on your data: ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Load the Covid Locations dataset into the notebook."),(0,r.kt)("li",{parentName:"ul"},"Print out the schema and the first few rows of data to check it has imported correctly."),(0,r.kt)("li",{parentName:"ul"},"Change a column name: rename ",(0,r.kt)("inlineCode",{parentName:"li"},"location")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"country"),"."),(0,r.kt)("li",{parentName:"ul"},"Load the Covid Vaccinations dataset into the notebook."),(0,r.kt)("li",{parentName:"ul"},"Cast a column to a different type e.g. a string date to date type."),(0,r.kt)("li",{parentName:"ul"},"Join the two tables to a single output using the ",(0,r.kt)("inlineCode",{parentName:"li"},"country")," column.")))),(0,r.kt)("h3",{id:"2-testing-the-finished-job-in-aws-glue"},"2. Testing the finished job in AWS glue"),(0,r.kt)("p",null,"You\u2019ll take the following steps before productionising your job, to check it runs smoothly in the AWS glue environment (it should, because the notebook runs against glue).\nIt will be an opportunity for you to try logging.\nAs we\u2019re just testing, we won\u2019t write any Terraform and we won\u2019t schedule the job.\nWe\u2019ll also delete our job at the end.\nIf you need more detailed instructions at any point checkout ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio"},"the guide to set up an ETL job"),"."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Login to AWS pre-production acccount via the ",(0,r.kt)("a",{parentName:"p",href:"https://hackney.awsapps.com/start#/"},"Hackney SSO"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Set up your new job in Glue Studio."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Go to ",(0,r.kt)("a",{parentName:"li",href:"https://eu-west-2.console.aws.amazon.com/gluestudio/home?region=eu-west-2#/jobs"},"AWS Glue Studio"),' and open the Template job, called "stg job_template".'),(0,r.kt)("li",{parentName:"ul"},"Familiarise yourself with the steps (reading, transforming and writing data) and note the differences compared to the Notebook template."),(0,r.kt)("li",{parentName:"ul"},'Clone the job (from Actions) and rename it with your name and remove stg from the prefix, for example "jane doe template".')),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"Cloning a glue job",src:a(8184).Z}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Write your job."),(0,r.kt)("p",{parentName:"li"},"Paste your code from the notebook into the template. (Cells can be merged in Jupyter by holding shift and selecting the cells, then hitting shift+M)."),(0,r.kt)("p",{parentName:"li"},"For the variables defined at the top of the notebook, you will use the \u2018Job details\u2019 tab instead of writing them in the script.\nThe Job parameters panel can be found under Advanced properties."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"job parameters",src:a(1124).Z}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Run your job.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Review the run result logs.\nSee the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio#monitoring-a-glue-job-run"},"monitoring section")," of the using glue studio guide for an explanation on how to do this.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Check the data wrote correctly into ",(0,r.kt)("a",{parentName:"p",href:"https://s3.console.aws.amazon.com/s3/home?region=eu-west-2"},"S3"),".\nTo do this, follow the same steps in the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1#6-crawling-the-ingested-data-to-make-it-available-in-the-glue-catalogue"},"last section of module 1"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://eu-west-2.console.aws.amazon.com/glue/home?region=eu-west-2#catalog:tab=crawlers"},"Crawl")," the results. (Using the crawler named \u201csandbox-refined-zone\u201d).")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Check the data in ",(0,r.kt)("a",{parentName:"p",href:"https://eu-west-2.console.aws.amazon.com/athena/home?region=eu-west-2#/query-editor/"},"Athena")," - (",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/querying-and-analysing-data/querying-data-using-sql"},"playbook"),").")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Remove the temporary resources that you created (glue job and S3 files) from the console."))),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\ud83c\udf89 Congratulations! You have completed Module 2!")))}m.isMDXComponent=!0},8184:function(e,t,a){t.Z=a.p+"assets/images/cloning_jobs-c2503e064e6e9ecf46dbfa06882c3695.png"},1124:function(e,t,a){t.Z=a.p+"assets/images/job_parameters-a3dbe41df15b36bdcb26ce05edb564cc.png"}}]);