"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[8381],{3905:function(e,t,r){r.d(t,{Zo:function(){return s},kt:function(){return f}});var o=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function c(e,t){if(null==e)return{};var r,o,n=function(e,t){if(null==e)return{};var r,o,n={},a=Object.keys(e);for(o=0;o<a.length;o++)r=a[o],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)r=a[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var p=o.createContext({}),u=function(e){var t=o.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},s=function(e){var t=u(e.components);return o.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},l=o.forwardRef((function(e,t){var r=e.components,n=e.mdxType,a=e.originalType,p=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),l=u(r),f=n,m=l["".concat(p,".").concat(f)]||l[f]||d[f]||a;return r?o.createElement(m,i(i({ref:t},s),{},{components:r})):o.createElement(m,i({ref:t},s))}));function f(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var a=r.length,i=new Array(a);i[0]=l;var c={};for(var p in t)hasOwnProperty.call(t,p)&&(c[p]=t[p]);c.originalType=e,c.mdxType="string"==typeof e?e:n,i[1]=c;for(var u=2;u<a;u++)i[u]=r[u];return o.createElement.apply(null,i)}return o.createElement.apply(null,r)}l.displayName="MDXCreateElement"},7623:function(e,t,r){r.r(t),r.d(t,{assets:function(){return s},contentTitle:function(){return p},default:function(){return f},frontMatter:function(){return c},metadata:function(){return u},toc:function(){return d}});var o=r(3117),n=r(102),a=(r(7294),r(3905)),i=["components"],c={title:"Production to pre-production data sync",description:"Overview of how data is copied from production to pre-production",tags:["playbook"],layout:"layout"},p=void 0,u={unversionedId:"docs/production-to-pre-production-sync",id:"docs/production-to-pre-production-sync",title:"Production to pre-production data sync",description:"Overview of how data is copied from production to pre-production",source:"@site/docs/docs/production-to-pre-production-sync.md",sourceDirName:"docs",slug:"/docs/production-to-pre-production-sync",permalink:"/Data-Platform-Playbook/docs/production-to-pre-production-sync",draft:!1,editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/docs/production-to-pre-production-sync.md",tags:[{label:"playbook",permalink:"/Data-Platform-Playbook/tags/playbook"}],version:"current",frontMatter:{title:"Production to pre-production data sync",description:"Overview of how data is copied from production to pre-production",tags:["playbook"],layout:"layout"},sidebar:"docs",previous:{title:"Import spreadsheets from G Drive",permalink:"/Data-Platform-Playbook/docs/import-spreadsheet-from-g-drive"},next:{title:"Redshift - Creating users, databases and exposing data from Glue",permalink:"/Data-Platform-Playbook/docs/redshift"}},s={},d=[{value:"Architecture",id:"architecture",level:2},{value:"Process",id:"process",level:2}],l={toc:d};function f(e){var t=e.components,c=(0,n.Z)(e,i);return(0,a.kt)("wrapper",(0,o.Z)({},l,c,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This section explains the process used to copy data from the data platform production environment into pre-production"),(0,a.kt)("h2",{id:"architecture"},"Architecture"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Production to pre production sync architecture",src:r(8770).Z,width:"801",height:"722"})),(0,a.kt)("h2",{id:"process"},"Process"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"When the CI/CD pipeline runs in Github a custom Docker image is built and pushed to the Elastic Container Registry in the Data Platform Production environment."),(0,a.kt)("li",{parentName:"ol"},"One Elastic Container Service for each zone is then created by Terraform in the form of Fargate tasks. These three tasks are configured by Terraform to run on a schedule. At the time of writing this schedule is once a day at 11pm."),(0,a.kt)("li",{parentName:"ol"},"When a task is triggered by the schedule the custom scripts inside the docker container execute S3 sync commands which move a configurable period of data from the production S3 bucket to the equivalent pre-production S3 bucket"),(0,a.kt)("li",{parentName:"ol"},"The script then deletes any data in the pre-production bucket that is older than the configured period"),(0,a.kt)("li",{parentName:"ol"},"At the time of writing this configurable period is 90 days")))}f.isMDXComponent=!0},8770:function(e,t,r){t.Z=r.p+"assets/images/prod-to-pre-prod-sync-architecture-8d6adf03ec92d8a03851ba975e5b03e8.png"}}]);