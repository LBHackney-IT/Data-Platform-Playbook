"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[1234],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return h}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),u=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),p=u(a),h=r,m=p["".concat(l,".").concat(h)]||p[h]||d[h]||s;return a?n.createElement(m,i(i({ref:t},c),{},{components:a})):n.createElement(m,i({ref:t},c))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,i=new Array(s);i[0]=p;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var u=2;u<s;u++)i[u]=a[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},7443:function(e,t,a){a.r(t),a.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return h},frontMatter:function(){return o},metadata:function(){return u},toc:function(){return d}});var n=a(3117),r=a(102),s=(a(7294),a(3905)),i=["components"],o={},l="Spike: Full-text address search with fuzzy matching.",u={unversionedId:"spikes/templates/example",id:"spikes/templates/example",title:"Spike: Full-text address search with fuzzy matching.",description:"Postgres Tools vs Elasticsearch",source:"@site/docs/spikes/templates/example.md",sourceDirName:"spikes/templates",slug:"/spikes/templates/example",permalink:"/Data-Platform-Playbook/spikes/templates/example",draft:!1,editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/spikes/templates/example.md",tags:[],version:"current",frontMatter:{}},c={},d=[{value:"Postgres Tools vs Elasticsearch",id:"postgres-tools-vs-elasticsearch",level:3},{value:"Objective",id:"objective",level:2},{value:"Considerations",id:"considerations",level:2},{value:"Findings",id:"findings",level:2},{value:"Postgres:",id:"postgres",level:3},{value:"Elasticsearch:",id:"elasticsearch",level:3}],p={toc:d};function h(e){var t=e.components,a=(0,r.Z)(e,i);return(0,s.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"spike-full-text-address-search-with-fuzzy-matching"},"Spike: Full-text address search with fuzzy matching."),(0,s.kt)("h3",{id:"postgres-tools-vs-elasticsearch"},"Postgres Tools vs Elasticsearch"),(0,s.kt)("h2",{id:"objective"},"Objective"),(0,s.kt)("p",null,"We want to determine which tools or technologies would be best for us to use to implement a full-text address search with fuzzy matching. This spike focused on two possibilities:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Postgres tools: We have a live Postgres RDS instance with address data."),(0,s.kt)("li",{parentName:"ul"},"Elasticsearch: It is a popular search engine & analytics tool.")),(0,s.kt)("h2",{id:"considerations"},"Considerations"),(0,s.kt)("p",null,"For this spike, a few user scenarios were used to determine which tool would be appropriate in fulfilling our desired address matching requirements:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Free text search across all address lines, i.e. Line1, Line2, Line3 & Line4."),(0,s.kt)("li",{parentName:"ul"},"Abbreviations of common street names (e.g. str, rd) are accepted."),(0,s.kt)("li",{parentName:"ul"},"Spelling mistakes are allowed."),(0,s.kt)("li",{parentName:"ul"},"Names with/ without an apostrophe return expected results."),(0,s.kt)("li",{parentName:"ul"},"Variations in describing address, e.g. Flat A 100 Mare Street vs 100A Mare Street."),(0,s.kt)("li",{parentName:"ul"},"Match proper names regardless of the words street, road, lane, etc. e.g Cromwell street query should also return Cromwell Avenue matches.")),(0,s.kt)("h2",{id:"findings"},"Findings"),(0,s.kt)("h3",{id:"postgres"},"Postgres:"),(0,s.kt)("p",null,"Postgres has quite a number of tools (or extensions) that we can install on our AWS RDS instance giving us the functionality that we want for our full-text search.\nWith Postgres we can:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Parse address strings into tokens (or lexemes). Tokenising should allow mapping of words in a query even if the way the user inputs the query varies e.g:",(0,s.kt)("ul",{parentName:"li"},(0,s.kt)("li",{parentName:"ul"},"Saved string: \u201cTry not to become a man of success, but rather try to become a man of value\u201d"),(0,s.kt)("li",{parentName:"ul"},"Tokens (or lexemes) created: 'becom', 'man', 'rather', 'success', 'tri', 'valu'"),(0,s.kt)("li",{parentName:"ul"},"User one query: \u201cTrying not to become a man of success\u201d"),(0,s.kt)("li",{parentName:"ul"},"User two query: \u201cBecoming a valued man\u201d"),(0,s.kt)("li",{parentName:"ul"},"Both queries (after tokenising as well) should return the saved string. Note: Tokenising removes stop words like e.g \u2018the\u2019, \u2018a\u2019, \u2018of\u2019, etc."),(0,s.kt)("li",{parentName:"ul"},"We can structure how to get the most relevant matches first by adding rankings to specific columns when queried."),(0,s.kt)("li",{parentName:"ul"},"We can add custom dictionaries that would hold any stop words we don\u2019t want to be ignored and can also hold synonyms for words e.g apartment vs flat. Str vs street."),(0,s.kt)("li",{parentName:"ul"},"Entity framework has support for Postgres full-text searching.\nThis is a quick overview of what Postgres full-text searching can offer us. The documentation for implementing this is very extensive and detailed.")))),(0,s.kt)("p",null,"####Limitation\nCurrently AWS RDS doesn\u2019t support custom dictionaries. This is because custom dictionaries are created as files that need to be uploaded into the database. You currently can\u2019t do this in RDS which would affect synonym and stop word matching."),(0,s.kt)("p",null,"####Suggestion\nIt might be possible to get around this by how we parse the user query i.e the parsed query for full-text search would use boolean operators, \u201cAND\u201d, \u201cOR\u201d, \u201cNOT\u201d. We would most likely use AND operations to get more relevant matches but there might be a way to use OR operators before certain abbreviations/synonyms but this would likely be custom code and could get a bit unwieldy. This also might result in more irrelevant matches but matches nonetheless whereas using just AND would return nothing."),(0,s.kt)("h3",{id:"elasticsearch"},"Elasticsearch:"),(0,s.kt)("p",null,"This is a search and analytics engine tool so has been designed to tackle the full-text searching to a specialised degree. To use Elasticsearch we would need to get the data we want to index into it but if we use AWS Elasticsearch this can be accomplished by DMS."),(0,s.kt)("p",null,"Getting data in Elasticsearch also requires mapping, however, we don\u2019t need to transfer all the data in the database. Might need more clarification on this but it sounds like an efficient way is to only transfer and index the data related to address search queries e.g the address line columns and postcode."),(0,s.kt)("p",null,"Elasticsearch also can:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Parse address strings into tokens (or lexemes) using its analysers."),(0,s.kt)("li",{parentName:"ul"},"Can install packages that add custom dictionaries of synonyms or words to ignore or stop words to not ignore."),(0,s.kt)("li",{parentName:"ul"},"Can also add weights for ranking.\nElasticsearch comes with an extensive toolset for searching, analysing data and returning the relevant matches and can be integrated into dotnet project by using a package called NEST.")),(0,s.kt)("p",null,"####Limitation\nThis is would be a separate tool that requires configuration and some understanding of what we should implement and don\u2019t need from Elasticsearch."),(0,s.kt)("p",null,"AWS has an Elasticsearch service we could spin up in our AWS environments. If we use AWS Elasticsearch we can benefit from using DMS to get the data we need into it, however, if we do not use AWS Elasticsearch, we would need to create a script to import the data into our Elasticsearch instance."),(0,s.kt)("p",null,"Using AWS Elasticsearch means we\u2019ll be adding an additional tool to our current stack in AWS and this would need to be managed and maintained. It also means that we would be adding an additional cost to the running of the stack. There is a free tier option but we would be charged for usages over that limit."),(0,s.kt)("p",null,"####Suggestion\nFrom reading the ONS paper on address matching, Elasticsearch was being implemented for retrieving addresses. Since this paper was focused on tackling the address matching problem, it might be worth using this as a tool for indexing and searching rather than relying on database tools."),(0,s.kt)("p",null,"We currently have indexes in the Postgres DB but it might be worth understanding a bit more about the indexing in Elasticsearch and whether these would have an effect on query performance compared to what we have in Postgres."),(0,s.kt)("p",null,"In our case, we might be able to use Elasticsearch as our indexing tool for a subset of data, retrieve a list of matching ids and then query the database using these ids, which could result in faster retrieval but this needs to be checked."),(0,s.kt)("p",null,"##Helpful Resources/Documentation"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Postgres documentation on Full-Text Searching")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Postgres Full-Text Search with Entity Framework Core")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Postgres full-text search is Good Enough! Blog")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Postgres Full-Text Search How-To Video")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Setting up Elasticsearch with .Net and Docker Blog")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Amazon Elasticsearch Pricing")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Amazon Elasticsearch Overview")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Querying Elasticsearch using the Search API")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Using DMS to migrate data into Elasticsearch"))))}h.isMDXComponent=!0}}]);