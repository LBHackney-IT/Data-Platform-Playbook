"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[8313],{3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return c}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=p(a),c=o,h=m["".concat(s,".").concat(c)]||m[c]||d[c]||r;return a?n.createElement(h,i(i({ref:t},u),{},{components:a})):n.createElement(h,i({ref:t},u))}));function c(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},4910:function(e,t,a){a.r(t),a.d(t,{assets:function(){return u},contentTitle:function(){return s},default:function(){return c},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return d}});var n=a(3117),o=a(102),r=(a(7294),a(3905)),i=["components"],l={title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",layout:"playbook_js",tags:["training"]},s="Module 2 - Transforming data & writing to the refined zone",p={unversionedId:"training-modules/module-2",id:"training-modules/module-2",title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",source:"@site/docs/training-modules/module-2.md",sourceDirName:"training-modules",slug:"/training-modules/module-2",permalink:"/Data-Platform-Playbook/training-modules/module-2",draft:!1,editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/training-modules/module-2.md",tags:[{label:"training",permalink:"/Data-Platform-Playbook/tags/training"}],version:"current",frontMatter:{title:"Module 2 - Transforming data to refined zone",description:"Training Module 2",layout:"playbook_js",tags:["training"]},sidebar:"docs",previous:{title:"Module 1 - Ingesting data from Google Sheets",permalink:"/Data-Platform-Playbook/training-modules/module-1"},next:{title:"Ingesting Academy data onto the Data Platform",permalink:"/Data-Platform-Playbook/docs/academy-ingestion"}},u={},d=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step-by-step instructions",id:"step-by-step-instructions",level:2},{value:"1. Developing the job script in a Jupyter notebook",id:"1-developing-the-job-script-in-a-jupyter-notebook",level:3},{value:"2. Testing the finished job in AWS glue",id:"2-testing-the-finished-job-in-aws-glue",level:3}],m={toc:d};function c(e){var t=e.components,l=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,n.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"module-2---transforming-data--writing-to-the-refined-zone"},"Module 2 - Transforming data & writing to the refined zone"),(0,r.kt)("p",null,"In this module you will manipulate the data that you loaded into the Data Platform raw zone in ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1"},"module 1"),".\nYou will save the result of your work into the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/glossary#refined-zone"},"refined zone")," of the data platform.\nThe refined zone is for data that has been enhanced or enriched and is \u2018ready\u2019 for analysis.\nYou will be using ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/api/python/"},"PySpark")," to code your job, and ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/glue/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc"},"AWS Glue")," to run it. You will create your code in a Jupyter Notebook environment running in AWS Sagemaker before copying it to the AWS console.\nJupyter notebooks are a convenient way to test code locally as Glue Studio is not so straightforward for code development (despite what the name implies!). You can read more about Jupyter notebooks ",(0,r.kt)("a",{parentName:"p",href:"https://jupyter.org/"},"here"),"."),(0,r.kt)("p",null,"This module is all about prototyping within a sandbox environment and therefore we won\u2019t be pushing any code to the Data Platform GitHub repository."),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,"You\u2019ll write a few lines of code in PySpark which will include reading data from S3, joining the two Covid datasets together and then writing the newly created dataset back to S3 in the refined zone. Then, you will be working in the console, running your job and checking your data like in Module 1. "),(0,r.kt)("p",null,"PySpark is an interface that uses the Python programming language to access the Apache Spark cluster-computing framework; therefore the syntax will seem a bit different if you have used Python packages such as Pandas or NumPy before."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Please ensure that both ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-0"},"Module 0")," and ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1"},"Module 1")," is completed before proceeding.\nYou will need the names of the tables that were created from completing Module 1."),(0,r.kt)("h2",{id:"step-by-step-instructions"},"Step-by-step instructions"),(0,r.kt)("h3",{id:"1-developing-the-job-script-in-a-jupyter-notebook"},"1. Developing the job script in a Jupyter notebook"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Launch the sandbox notebook following ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker"},"this guide"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Open the notebook template called ",(0,r.kt)("inlineCode",{parentName:"p"},"using-pyspark.ipynb"),"."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Familiarise yourself with the steps (variables, reading, transforming and writing data)."),(0,r.kt)("li",{parentName:"ul"},"Duplicate the template, saving it in the sandbox folder, and rename it (you can append your name to the name of the file)."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Prototype your own ETL (Extract Transform Load) job to transform the data in PySpark.\nThe ",(0,r.kt)("a",{parentName:"p",href:"https://sparkbyexamples.com/pyspark-tutorial/"},"PySpark By Examples website")," is a handy resource to write your code. "),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Please try the following things on your data:")," "),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Load the Covid Locations dataset into the notebook.",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},'You will first need to set the variables in the first cell, see the "TODO" comments.\nThe datasets will be the same as the last step in Module 1 training.'))),(0,r.kt)("li",{parentName:"ul"},"Print out the schema and the first few rows of data to check it has imported correctly."),(0,r.kt)("li",{parentName:"ul"},"Change a column name: rename ",(0,r.kt)("inlineCode",{parentName:"li"},"location")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"country"),"."),(0,r.kt)("li",{parentName:"ul"},"Load the Covid Vaccinations dataset into the notebook - Repeat the 2 steps above. "),(0,r.kt)("li",{parentName:"ul"},"Cast a column to a different type e.g. a string date to date type."),(0,r.kt)("li",{parentName:"ul"},"Join the two tables to a single output using the ",(0,r.kt)("inlineCode",{parentName:"li"},"country")," column.")))),(0,r.kt)("h3",{id:"2-testing-the-finished-job-in-aws-glue"},"2. Testing the finished job in AWS glue"),(0,r.kt)("p",null,"You\u2019ll take the following steps before productionising your job, to check it runs smoothly in the AWS glue environment (it should, because the notebook runs against glue).\nIt will be an opportunity for you to try logging.\nAs we\u2019re just testing, we won\u2019t write any Terraform and we won\u2019t schedule the job.\nWe\u2019ll also delete our job at the end.\nIf you need more detailed instructions at any point checkout ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio"},"the guide to set up an ETL job"),"."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Login to AWS pre-production acccount via the ",(0,r.kt)("a",{parentName:"p",href:"https://hackney.awsapps.com/start#/"},"Hackney SSO"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Set up your new job in Glue Studio."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Go to ",(0,r.kt)("a",{parentName:"li",href:"https://eu-west-2.console.aws.amazon.com/gluestudio/home?region=eu-west-2#/jobs"},"AWS Glue Studio"),' and open the Template job, called "stg job_template".'),(0,r.kt)("li",{parentName:"ul"},'Clone the job (from Actions) and rename it with your name and remove "stg" from the prefix, for example "jane doe template".'),(0,r.kt)("li",{parentName:"ul"},"Open the job and familiarise yourself with the steps (reading, transforming and writing data) and note the differences compared to the Notebook template.")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"Cloning a glue job",src:a(9408).Z,width:"512",height:"223"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Write your job."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Paste your code from the notebook into the template, ignoring the first cell (Cells can be merged in Jupyter by holding ",(0,r.kt)("inlineCode",{parentName:"p"},"Shift")," and selecting the cells, then pressing ",(0,r.kt)("inlineCode",{parentName:"p"},"Shift+M")," on your keyboard).")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"For the variables defined in the first cell of your notebook, you will use the ",(0,r.kt)("inlineCode",{parentName:"p"},"Job details")," tab instead of writing them in the script.\nYou should define them in the ",(0,r.kt)("strong",{parentName:"p"},"Job parameters")," panel which can be found under ",(0,r.kt)("inlineCode",{parentName:"p"},"Advanced properties"),".\nYou should also update the S3 path in the ",(0,r.kt)("strong",{parentName:"p"},"Script path")," field to ",(0,r.kt)("inlineCode",{parentName:"p"},"s3://dataplatform-stg-glue-scripts/custom/"),". "))),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"job parameters",src:a(9493).Z,width:"512",height:"342"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Run your job.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Review the run result logs.\nSee the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio#monitoring-a-glue-job-run"},"monitoring section")," of the using Glue Studio guide for an explanation on how to do this.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Once your job status has changed from ",(0,r.kt)("inlineCode",{parentName:"p"},"Running")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"Succeeded")," you should check the data wrote correctly into ",(0,r.kt)("a",{parentName:"p",href:"https://s3.console.aws.amazon.com/s3/home?region=eu-west-2"},"S3"),".\nTo do this, follow the same steps in the ",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/training-modules/module-1#6-crawling-the-ingested-data-to-make-it-available-in-the-glue-catalogue"},"last section of Module 1"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://eu-west-2.console.aws.amazon.com/glue/home?region=eu-west-2#catalog:tab=crawlers"},"Crawl")," the results. (Using the crawler named \u201csandbox-refined-zone\u201d).")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Check the data in ",(0,r.kt)("a",{parentName:"p",href:"https://eu-west-2.console.aws.amazon.com/athena/home?region=eu-west-2#/query-editor/"},"Athena")," - (",(0,r.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/querying-and-analysing-data/querying-data-using-sql"},"playbook"),").")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Remove the temporary resources that you created in the AWS Console:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Glue job"),(0,r.kt)("li",{parentName:"ul"},"S3 files: check the S3 target location of your job for a reminder of where the data was written.")))),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\ud83c\udf89 Congratulations! You have completed Module 2!")))}c.isMDXComponent=!0},9408:function(e,t,a){t.Z=a.p+"assets/images/cloning_jobs-c2503e064e6e9ecf46dbfa06882c3695.png"},9493:function(e,t,a){t.Z=a.p+"assets/images/job_parameters-a3dbe41df15b36bdcb26ce05edb564cc.png"}}]);