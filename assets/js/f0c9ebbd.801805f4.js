"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[1590],{3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return f}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=c(a),f=o,m=p["".concat(l,".").concat(f)]||p[f]||d[f]||r;return a?n.createElement(m,s(s({ref:t},u),{},{components:a})):n.createElement(m,s({ref:t},u))}));function f(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=p;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var c=2;c<r;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},457:function(e,t,a){a.r(t),a.d(t,{assets:function(){return u},contentTitle:function(){return l},default:function(){return f},frontMatter:function(){return i},metadata:function(){return c},toc:function(){return d}});var n=a(3117),o=a(102),r=(a(7294),a(3905)),s=["components"],i={title:"Ingesting data from MSSQL database",description:"Investigate creating a reusable process for ingesting data from MS SQL and other types of databases",tags:["tech-spike"],layout:"layout"},l=void 0,c={unversionedId:"spikes/mssql-ingestion",id:"spikes/mssql-ingestion",title:"Ingesting data from MSSQL database",description:"Investigate creating a reusable process for ingesting data from MS SQL and other types of databases",source:"@site/docs/spikes/mssql-ingestion.md",sourceDirName:"spikes",slug:"/spikes/mssql-ingestion",permalink:"/Data-Platform-Playbook/spikes/mssql-ingestion",draft:!1,editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/spikes/mssql-ingestion.md",tags:[{label:"tech-spike",permalink:"/Data-Platform-Playbook/tags/tech-spike"}],version:"current",frontMatter:{title:"Ingesting data from MSSQL database",description:"Investigate creating a reusable process for ingesting data from MS SQL and other types of databases",tags:["tech-spike"],layout:"layout"},sidebar:"docs",previous:{title:"Datahub deployment",permalink:"/Data-Platform-Playbook/spikes/datahub-deployment"},next:{title:"Qlik Integration",permalink:"/Data-Platform-Playbook/spikes/qlik-integration"}},u={},d=[{value:"Context",id:"context",level:2},{value:"Objective",id:"objective",level:2},{value:"Decision",id:"decision",level:2},{value:"Considerations",id:"considerations",level:2},{value:"Consequences",id:"consequences",level:2}],p={toc:d};function f(e){var t=e.components,i=(0,o.Z)(e,s);return(0,r.kt)("wrapper",(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Ingesting data from MS SQL database",src:a(1207).Z,width:"916",height:"325"})),(0,r.kt)("h2",{id:"context"},"Context"),(0,r.kt)("p",null,"The Data Platform needs to ingest Academy Insights data from an MS SQL server database but doesn't currently have a process in place to accomplish this"),(0,r.kt)("h2",{id:"objective"},"Objective"),(0,r.kt)("p",null,"Create a reusable process that will enable the ingestion of data from Academy's MS SQL server database and other types of databases"),(0,r.kt)("h2",{id:"decision"},"Decision"),(0,r.kt)("p",null,"A JDBC connection (Glue Connection) can be used to get access and connect to the Academy's MS SQL server database.\nThe JDBC connection is used in both the AWS Glue crawler and AWS Glue job (seen in the diagram) to extract data from the SQL views and tables."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"JDBC is a low-level API for making database connections and handling SQL queries and responses. ")),(0,r.kt)("p",null,"With the established connection, a Glue Crawler can crawl the source database (selecting specific tables) and then populate a Glue Catalog database\nwith the tables' structures; such as table schemas and other metadata of the specified tables from the MS SQL database."),(0,r.kt)("p",null,"The tables can be read from the Glue Catalog Database via a Glue job using the same JDBC connection that has connected to the MS SQL source database.\nAt this point, the data can be transformed as necessary and then written out to S3 and crawled, making it available for querying in Athena and other Business Intelligence tools such as Google Data Studio and Qlik."),(0,r.kt)("h2",{id:"considerations"},"Considerations"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Pulling data into the Data Platform from the MS SQL server database will likely be a very load intensive task on the database and can take some time"),(0,r.kt)("li",{parentName:"ul"},"Some questions that still need answering:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"How can we minimise the impact to users on the Academy Insights database?"),(0,r.kt)("li",{parentName:"ul"},"How often do we pull the data in?"),(0,r.kt)("li",{parentName:"ul"},"How can we ensure we only pull the latest changes to the Data Platform?"),(0,r.kt)("li",{parentName:"ul"},"What needs to be done to the data once it's on the platform so that it's ready to be used by the team for analysis?")))),(0,r.kt)("h2",{id:"consequences"},"Consequences"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"We have a reusable process for ingesting data from different types of databases"),(0,r.kt)("li",{parentName:"ul"},"There could potentially be added load on the Academy Insights database which could affect performance without specific measures in place to mitigate this")))}f.isMDXComponent=!0},1207:function(e,t,a){t.Z=a.p+"assets/images/ingesting-data-from-mssql-database.drawio-5a5343069fbd455a21afb798fe2cf808.png"}}]);