"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[8609],{977:a=>{a.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"About","items":[{"type":"link","label":"About the Data Platform","href":"/Data-Platform-Playbook/","docId":"introduction","unlisted":false},{"type":"link","label":"About this Playbook","href":"/Data-Platform-Playbook/about-playbook","docId":"about-playbook","unlisted":false},{"type":"link","label":"Zones","href":"/Data-Platform-Playbook/zones","docId":"zones","unlisted":false},{"type":"link","label":"Environments","href":"/Data-Platform-Playbook/environments","docId":"environments","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Playbook","items":[{"type":"category","label":"Getting set up on the platform","items":[{"type":"link","label":"Introduction","href":"/Data-Platform-Playbook/playbook/getting-set-up/","docId":"playbook/getting-set-up/index","unlisted":false},{"type":"link","label":"Getting started with the local PySpark environment","href":"/Data-Platform-Playbook/playbook/getting-set-up/local-pyspark-environment","docId":"playbook/getting-set-up/local-pyspark-environment","unlisted":false},{"type":"link","label":"Local Notebook Environment Setup","href":"/Data-Platform-Playbook/playbook/getting-set-up/notebook-setup","docId":"playbook/getting-set-up/notebook-setup","unlisted":false},{"type":"link","label":"Onboarding new departments to the platform","href":"/Data-Platform-Playbook/playbook/getting-set-up/onboarding-new-departments-to-the-platform","docId":"playbook/getting-set-up/onboarding-new-departments-to-the-platform","unlisted":false},{"type":"link","label":"Onboarding new users to the platform","href":"/Data-Platform-Playbook/playbook/getting-set-up/onboarding-new-users-to-the-platform","docId":"playbook/getting-set-up/onboarding-new-users-to-the-platform","unlisted":false},{"type":"link","label":"Using GitHub","href":"/Data-Platform-Playbook/playbook/getting-set-up/using-github","docId":"playbook/getting-set-up/using-github","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Elements of the platform","items":[{"type":"link","label":"Data Catalogue","href":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-catalogue","docId":"playbook/elements-of-the-platform/data-catalogue","unlisted":false},{"type":"link","label":"Data Lake","href":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-lake","docId":"playbook/elements-of-the-platform/data-lake","unlisted":false},{"type":"link","label":"Data Warehouse","href":"/Data-Platform-Playbook/playbook/elements-of-the-platform/data-warehouse","docId":"playbook/elements-of-the-platform/data-warehouse","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Finding data on the platform","items":[{"type":"link","label":"Using the data catalogue","href":"/Data-Platform-Playbook/playbook/finding-data/data-catalogue","docId":"playbook/finding-data/data-catalogue","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Getting access to data","items":[{"type":"link","label":"Connecting to the Data Platform from Tableau","href":"/Data-Platform-Playbook/playbook/getting-access-to-data/Tableau-to-redshift","docId":"playbook/getting-access-to-data/Tableau-to-redshift","unlisted":false},{"type":"link","label":"Introduction","href":"/Data-Platform-Playbook/playbook/getting-access-to-data/","docId":"playbook/getting-access-to-data/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Ingesting data","items":[{"type":"link","label":"Types of data and ingestion process","href":"/Data-Platform-Playbook/playbook/ingesting-data/what-data-are-we-ingesting","docId":"playbook/ingesting-data/what-data-are-we-ingesting","unlisted":false},{"type":"link","label":"Ingesting data from Google Sheets","href":"/Data-Platform-Playbook/playbook/ingesting-data/google-sheets-import","docId":"playbook/ingesting-data/google-sheets-import","unlisted":false},{"type":"link","label":"Ingest manually uploaded csv files","href":"/Data-Platform-Playbook/playbook/ingesting-data/manual-ingest-of-csv-files","docId":"playbook/ingesting-data/manual-ingest-of-csv-files","unlisted":false},{"type":"link","label":"Ingest spreadsheet files from G Drive","href":"/Data-Platform-Playbook/playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive","docId":"playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive","unlisted":false},{"type":"link","label":"Ingesting RDS snapshot into the Data Platform Landing Zone","href":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone","docId":"playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone","unlisted":false},{"type":"link","label":"Ingesting data from databases into the Data Platform","href":"/Data-Platform-Playbook/playbook/ingesting-data/database-ingestion","docId":"playbook/ingesting-data/database-ingestion","unlisted":false},{"type":"link","label":"Ingesting Dynamo DB tables into the Landing Zone","href":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-dynamo-db-tables","docId":"playbook/ingesting-data/ingesting-dynamo-db-tables","unlisted":false},{"type":"link","label":"Ingesting new data entities via event streaming","href":"/Data-Platform-Playbook/playbook/ingesting-data/event-streaming","docId":"playbook/ingesting-data/event-streaming","unlisted":false},{"type":"link","label":"Ingesting data from an API to the Data Platform","href":"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-api-data","docId":"playbook/ingesting-data/ingesting-api-data","unlisted":false},{"type":"link","label":"Production to pre-production data sync","href":"/Data-Platform-Playbook/playbook/ingesting-data/production-to-pre-production-sync","docId":"playbook/ingesting-data/production-to-pre-production-sync","unlisted":false},{"type":"link","label":"Tips on writing an API Ingestion script for AWS Lambda","href":"/Data-Platform-Playbook/playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script","docId":"playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script","unlisted":false},{"type":"link","label":"Using Watermarks to Record AWS GLue Job States Between Runs","href":"/Data-Platform-Playbook/playbook/ingesting-data/using-watermarks-to-record-job-states","docId":"playbook/ingesting-data/using-watermarks-to-record-job-states","unlisted":false},{"type":"link","label":"How to create a Lambda function for data ingestion on the Data Analytics Platform","href":"/Data-Platform-Playbook/playbook/ingesting-data/creating-a-lambda-function-step-by-step","docId":"playbook/ingesting-data/creating-a-lambda-function-step-by-step","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Exporting data","items":[{"type":"link","label":"Export data catalog table or view to Google Sheets","href":"/Data-Platform-Playbook/playbook/exporting-data/save-glue-catalog-to-google-sheet","docId":"playbook/exporting-data/save-glue-catalog-to-google-sheet","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Transforming data","items":[{"type":"category","label":"Guides to testing in the platform","items":[{"type":"link","label":"Guide to testing data quality in Glue Jobs","href":"/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide","docId":"playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide","unlisted":false},{"type":"link","label":"Guide to unit testing on the Data Platform","href":"/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide","docId":"playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Using AWS Glue","items":[{"type":"link","label":"Using Glue Studio","href":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio","docId":"playbook/transforming-data/using-aws-glue/using-glue-studio","unlisted":false},{"type":"link","label":"Deploying Glue jobs to the Data Platform","href":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs","docId":"playbook/transforming-data/using-aws-glue/deploy-glue-jobs","unlisted":false},{"type":"link","label":"Prototyping glue jobs in a notebook","href":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker","docId":"playbook/transforming-data/using-aws-glue/using-sagemaker","unlisted":false},{"type":"link","label":"Optimizing Glue jobs","href":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs","docId":"playbook/transforming-data/using-aws-glue/optimizing-glue-jobs","unlisted":false},{"type":"category","label":"Practical examples","items":[{"type":"link","label":"Scheduling Liberator Glue Jobs","href":"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs","docId":"playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs","unlisted":false},{"type":"link","label":"Glue Studio workshop with Parking Analysts","href":"/Data-Platform-Playbook/workshop/aws_glue_studio_parking","docId":"workshop/aws_glue_studio_parking","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Querying and analysing data","items":[{"type":"category","label":"Time Series Analysis","items":[{"type":"link","label":"1. Introduction to Time Series Helpers","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/introduction","docId":"playbook/querying-and-analysing-data/time-series-analysis/introduction","unlisted":false},{"type":"link","label":"2. Basic Time Series helpers","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/basic_helpers","docId":"playbook/querying-and-analysing-data/time-series-analysis/basic_helpers","unlisted":false},{"type":"link","label":"3. Step by Step Guide to Forecasting","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example","docId":"playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example","unlisted":false},{"type":"link","label":"Exponential Smoothing ETS","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets","docId":"playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets","unlisted":false},{"type":"link","label":"Holt Winters ETS","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets","docId":"playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Connecting to the Redshift cluster from Google Data Studio","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio","docId":"playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio","unlisted":false},{"type":"link","label":"Create a data extract in Google Data Studio","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/create_a_data_extract_in_GDS","docId":"playbook/querying-and-analysing-data/create_a_data_extract_in_GDS","unlisted":false},{"type":"link","label":"Geospatial enrichment","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/geospatial-enrichments","docId":"playbook/querying-and-analysing-data/geospatial-enrichments","unlisted":false},{"type":"link","label":"Querying the Data Platform using SQL within AWS Athena","href":"/Data-Platform-Playbook/playbook/querying-and-analysing-data/querying-data-using-sql","docId":"playbook/querying-and-analysing-data/querying-data-using-sql","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Training Modules","items":[{"type":"category","label":"Main Modules","items":[{"type":"link","label":"Getting started with training","href":"/Data-Platform-Playbook/training-modules/module-0","docId":"training-modules/module-0","unlisted":false},{"type":"link","label":"Ingesting data from Google Sheets","href":"/Data-Platform-Playbook/training-modules/module-1","docId":"training-modules/module-1","unlisted":false},{"type":"link","label":"Transforming data to refined zone using Sagemaker","href":"/Data-Platform-Playbook/training-modules/module-2","docId":"training-modules/module-2","unlisted":false},{"type":"link","label":"Deploying a job in AWS Glue","href":"/Data-Platform-Playbook/training-modules/module-3","docId":"training-modules/module-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Qlik Modules","items":[{"type":"link","label":"Module 1 - Introduction to Qlik","href":"/Data-Platform-Playbook/training-modules/Qlik/qlik-module-1","docId":"training-modules/Qlik/qlik-module-1","unlisted":false},{"type":"link","label":"Module 2 - Developing a simple dashboard","href":"/Data-Platform-Playbook/training-modules/Qlik/qlik-module-2","docId":"training-modules/Qlik/qlik-module-2","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Technical Documentation","items":[{"type":"link","label":"CD Process","href":"/Data-Platform-Playbook/docs/CD-process","docId":"docs/CD-process","unlisted":false},{"type":"link","label":"CI Process","href":"/Data-Platform-Playbook/docs/CI-process","docId":"docs/CI-process","unlisted":false},{"type":"link","label":"Ingesting Academy data onto the Data Platform","href":"/Data-Platform-Playbook/docs/academy-ingestion","docId":"docs/academy-ingestion","unlisted":false},{"type":"link","label":"Alloy data ingestion","href":"/Data-Platform-Playbook/docs/alloy-ingestion","docId":"docs/alloy-ingestion","unlisted":false},{"type":"link","label":"Auto-adjusting AWS Budget Alerts","href":"/Data-Platform-Playbook/docs/auto-adjusting-aws-budget","docId":"docs/auto-adjusting-aws-budget","unlisted":false},{"type":"link","label":"Backdated Liberator data ingestion","href":"/Data-Platform-Playbook/docs/backdated-liberator-ingestion","docId":"docs/backdated-liberator-ingestion","unlisted":false},{"type":"link","label":"Exporting database snapshots to the Data Platform Landing Zone","href":"/Data-Platform-Playbook/docs/exporting-snapshot-to-landing-zone","docId":"docs/exporting-snapshot-to-landing-zone","unlisted":false},{"type":"link","label":"Importing external files to the Data Platform Landing Zone","href":"/Data-Platform-Playbook/docs/import-external-files-to-landing-zone","docId":"docs/import-external-files-to-landing-zone","unlisted":false},{"type":"link","label":"Import spreadsheets from G Drive","href":"/Data-Platform-Playbook/docs/import-spreadsheet-from-g-drive","docId":"docs/import-spreadsheet-from-g-drive","unlisted":false},{"type":"link","label":"Liberator data ingestion","href":"/Data-Platform-Playbook/docs/liberator-ingestion","docId":"docs/liberator-ingestion","unlisted":false},{"type":"link","label":"Redshift - Creating users, databases and exposing data from Glue","href":"/Data-Platform-Playbook/docs/redshift","docId":"docs/redshift","unlisted":false},{"type":"link","label":"RingGo data ingestion","href":"/Data-Platform-Playbook/docs/ringgo-ingestion","docId":"docs/ringgo-ingestion","unlisted":false},{"type":"link","label":"Tascomi data ingestion","href":"/Data-Platform-Playbook/docs/tascomi-ingestion","docId":"docs/tascomi-ingestion","unlisted":false},{"type":"link","label":"VPC Peering Connection between Data Platform and Production APIs AWS accounts","href":"/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account","docId":"docs/vpc-peering-connection-dataplatform-and-production-apis-account","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"DAP\u21e8flow","items":[{"type":"link","label":"\ud83d\udcdaIntroduction","href":"/Data-Platform-Playbook/dap-airflow/introduction","docId":"dap-airflow/introduction","unlisted":false},{"type":"category","label":"\ud83d\udcdaOnboarding","items":[{"type":"link","label":"Begin here","href":"/Data-Platform-Playbook/dap-airflow/onboarding/begin","docId":"dap-airflow/onboarding/begin","unlisted":false},{"type":"link","label":"Welcome!","href":"/Data-Platform-Playbook/dap-airflow/onboarding/welcome","docId":"dap-airflow/onboarding/welcome","unlisted":false},{"type":"link","label":"AWS Console access","href":"/Data-Platform-Playbook/dap-airflow/onboarding/access-the-AWS-Management-Console","docId":"dap-airflow/onboarding/access-the-AWS-Management-Console","unlisted":false},{"type":"link","label":"AWS region","href":"/Data-Platform-Playbook/dap-airflow/onboarding/access-the-AWS-region","docId":"dap-airflow/onboarding/access-the-AWS-region","unlisted":false},{"type":"link","label":"Amazon Athena","href":"/Data-Platform-Playbook/dap-airflow/onboarding/access-my-Amazon-Athena-database","docId":"dap-airflow/onboarding/access-my-Amazon-Athena-database","unlisted":false},{"type":"link","label":"My current service data","href":"/Data-Platform-Playbook/dap-airflow/onboarding/access-my-current-service-data","docId":"dap-airflow/onboarding/access-my-current-service-data","unlisted":false},{"type":"link","label":"My service data history","href":"/Data-Platform-Playbook/dap-airflow/onboarding/access-my-service-data-history","docId":"dap-airflow/onboarding/access-my-service-data-history","unlisted":false},{"type":"link","label":"Query my service data","href":"/Data-Platform-Playbook/dap-airflow/onboarding/query-my-service-data","docId":"dap-airflow/onboarding/query-my-service-data","unlisted":false},{"type":"link","label":"Prototype simple transforms","href":"/Data-Platform-Playbook/dap-airflow/onboarding/prototype-simple-transforms","docId":"dap-airflow/onboarding/prototype-simple-transforms","unlisted":false},{"type":"link","label":"Prototype legacy transforms","href":"/Data-Platform-Playbook/dap-airflow/onboarding/prototype-legacy-transforms","docId":"dap-airflow/onboarding/prototype-legacy-transforms","unlisted":false},{"type":"link","label":"GitHub access","href":"/Data-Platform-Playbook/dap-airflow/onboarding/github-access","docId":"dap-airflow/onboarding/github-access","unlisted":false},{"type":"link","label":"GitHub branching","href":"/Data-Platform-Playbook/dap-airflow/onboarding/github-branch","docId":"dap-airflow/onboarding/github-branch","unlisted":false},{"type":"link","label":"Committing transforms","href":"/Data-Platform-Playbook/dap-airflow/onboarding/github-commit-transform","docId":"dap-airflow/onboarding/github-commit-transform","unlisted":false},{"type":"link","label":"GitHub pull requests","href":"/Data-Platform-Playbook/dap-airflow/onboarding/github-pull-request","docId":"dap-airflow/onboarding/github-pull-request","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"\ud83d\udcdaMigration onboarding","items":[{"type":"link","label":"Begin here","href":"/Data-Platform-Playbook/dap-airflow/parking/begin","docId":"dap-airflow/parking/begin","unlisted":false},{"type":"link","label":"Welcome!","href":"/Data-Platform-Playbook/dap-airflow/parking/welcome","docId":"dap-airflow/parking/welcome","unlisted":false},{"type":"link","label":"AWS Console access","href":"/Data-Platform-Playbook/dap-airflow/parking/access-the-AWS-Management-Console","docId":"dap-airflow/parking/access-the-AWS-Management-Console","unlisted":false},{"type":"link","label":"AWS region","href":"/Data-Platform-Playbook/dap-airflow/parking/access-the-AWS-region","docId":"dap-airflow/parking/access-the-AWS-region","unlisted":false},{"type":"link","label":"Amazon Athena","href":"/Data-Platform-Playbook/dap-airflow/parking/access-my-Amazon-Athena-database","docId":"dap-airflow/parking/access-my-Amazon-Athena-database","unlisted":false},{"type":"link","label":"My service data history","href":"/Data-Platform-Playbook/dap-airflow/parking/access-my-service-data-history","docId":"dap-airflow/parking/access-my-service-data-history","unlisted":false},{"type":"link","label":"My current service data","href":"/Data-Platform-Playbook/dap-airflow/parking/access-my-current-service-data","docId":"dap-airflow/parking/access-my-current-service-data","unlisted":false},{"type":"link","label":"Query my service data","href":"/Data-Platform-Playbook/dap-airflow/parking/query-my-service-data","docId":"dap-airflow/parking/query-my-service-data","unlisted":false},{"type":"link","label":"Prototype simple transforms","href":"/Data-Platform-Playbook/dap-airflow/parking/prototype-simple-transforms","docId":"dap-airflow/parking/prototype-simple-transforms","unlisted":false},{"type":"link","label":"Migrating transforms","href":"/Data-Platform-Playbook/dap-airflow/parking/migrating-transforms","docId":"dap-airflow/parking/migrating-transforms","unlisted":false},{"type":"link","label":"GitHub access","href":"/Data-Platform-Playbook/dap-airflow/parking/github-access","docId":"dap-airflow/parking/github-access","unlisted":false},{"type":"link","label":"GitHub branching","href":"/Data-Platform-Playbook/dap-airflow/parking/github-branch","docId":"dap-airflow/parking/github-branch","unlisted":false},{"type":"link","label":"Committing transforms","href":"/Data-Platform-Playbook/dap-airflow/parking/github-commit-transform","docId":"dap-airflow/parking/github-commit-transform","unlisted":false},{"type":"link","label":"Orchestrating transforms","href":"/Data-Platform-Playbook/dap-airflow/parking/github-orchestrate-transform","docId":"dap-airflow/parking/github-orchestrate-transform","unlisted":false},{"type":"link","label":"GitHub pull requests","href":"/Data-Platform-Playbook/dap-airflow/parking/github-pull-request","docId":"dap-airflow/parking/github-pull-request","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"\ud83d\udcdaUX","href":"/Data-Platform-Playbook/dap-airflow/ux","docId":"dap-airflow/ux","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Architecture Decision","items":[{"type":"link","label":"Introduction","href":"/Data-Platform-Playbook/architecture-decisions/","docId":"architecture-decisions/index","unlisted":false},{"type":"category","label":"Records","items":[{"type":"link","label":"Record architecture decisions - ADR 001","href":"/Data-Platform-Playbook/architecture-decisions/records/record-architecture-decisions","docId":"architecture-decisions/records/record-architecture-decisions","unlisted":false},{"type":"link","label":"Ingest Google Sheets Data - ADR 002","href":"/Data-Platform-Playbook/architecture-decisions/records/ingest-google-sheets-data","docId":"architecture-decisions/records/ingest-google-sheets-data","unlisted":false},{"type":"link","label":"Role-Based Access Control - ADR 003","href":"/Data-Platform-Playbook/architecture-decisions/records/role-based-access-control","docId":"architecture-decisions/records/role-based-access-control","unlisted":false},{"type":"link","label":"Partition Strategy - ADR 004","href":"/Data-Platform-Playbook/architecture-decisions/records/partition-strategy","docId":"architecture-decisions/records/partition-strategy","unlisted":false},{"type":"link","label":"Recovered Data - ADR 005","href":"/Data-Platform-Playbook/architecture-decisions/records/recovered-data","docId":"architecture-decisions/records/recovered-data","unlisted":false},{"type":"link","label":"Ingest SQL flat files - ADR 006","href":"/Data-Platform-Playbook/architecture-decisions/records/ingest-sql-flat-files","docId":"architecture-decisions/records/ingest-sql-flat-files","unlisted":false},{"type":"link","label":"Copy Liberator data from sftp to s3 - ADR 007","href":"/Data-Platform-Playbook/architecture-decisions/records/sftp-to-s3-lambda","docId":"architecture-decisions/records/sftp-to-s3-lambda","unlisted":false},{"type":"link","label":"Production Data in Staging - ADR 008","href":"/Data-Platform-Playbook/architecture-decisions/records/production-data-in-staging","docId":"architecture-decisions/records/production-data-in-staging","unlisted":false},{"type":"link","label":"Ingesting data from APIs - ADR 009","href":"/Data-Platform-Playbook/architecture-decisions/records/ingesting-data-from-apis","docId":"architecture-decisions/records/ingesting-data-from-apis","unlisted":false},{"type":"link","label":"Using pytest for verifying PySpark transformations - ADR 010","href":"/Data-Platform-Playbook/architecture-decisions/records/using-pytest-for-verifying-pyspark-transformations","docId":"architecture-decisions/records/using-pytest-for-verifying-pyspark-transformations","unlisted":false},{"type":"link","label":"Using DataHub as a Data Catalogue - ADR 011","href":"/Data-Platform-Playbook/architecture-decisions/records/using-datahub-as-a-data-catalogue","docId":"architecture-decisions/records/using-datahub-as-a-data-catalogue","unlisted":false},{"type":"link","label":"Using Event Streaming to Ingest Data - ADR 012","href":"/Data-Platform-Playbook/architecture-decisions/records/do-not-connect-to-production-databases","docId":"architecture-decisions/records/do-not-connect-to-production-databases","unlisted":false},{"type":"link","label":"Move Staging to Pre-Production - ADR 012","href":"/Data-Platform-Playbook/architecture-decisions/records/move-staging-to-pre-production","docId":"architecture-decisions/records/move-staging-to-pre-production","unlisted":false},{"type":"link","label":"Using Event Streaming to Ingest Data - ADR 013","href":"/Data-Platform-Playbook/architecture-decisions/records/using-event-streaming-to-ingest-data","docId":"architecture-decisions/records/using-event-streaming-to-ingest-data","unlisted":false},{"type":"link","label":"Initial Extract of Tenure Data  - ADR 014","href":"/Data-Platform-Playbook/architecture-decisions/records/initial-extract-of-tenure-data","docId":"architecture-decisions/records/initial-extract-of-tenure-data","unlisted":false},{"type":"link","label":"Spatial Data Processing - ADR 015","href":"/Data-Platform-Playbook/architecture-decisions/records/spatial-data-processing","docId":"architecture-decisions/records/spatial-data-processing","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Spikes","items":[{"type":"link","label":"Amundsen deployment","href":"/Data-Platform-Playbook/spikes/amundsen-deployment","docId":"spikes/amundsen-deployment","unlisted":false},{"type":"link","label":"Data Quality Testing","href":"/Data-Platform-Playbook/spikes/data-quality-testing","docId":"spikes/data-quality-testing","unlisted":false},{"type":"link","label":"Datahub deployment","href":"/Data-Platform-Playbook/spikes/datahub-deployment","docId":"spikes/datahub-deployment","unlisted":false},{"type":"link","label":"Ingesting data from MSSQL database","href":"/Data-Platform-Playbook/spikes/mssql-ingestion","docId":"spikes/mssql-ingestion","unlisted":false},{"type":"link","label":"Qlik Integration","href":"/Data-Platform-Playbook/spikes/qlik-integration","docId":"spikes/qlik-integration","unlisted":false},{"type":"link","label":"Sagemaker","href":"/Data-Platform-Playbook/spikes/sagemaker","docId":"spikes/sagemaker","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Glossary","href":"/Data-Platform-Playbook/glossary","docId":"glossary","unlisted":false},{"type":"link","label":"Roles","href":"/Data-Platform-Playbook/roles","docId":"roles","unlisted":false}]},"docs":{"about-playbook":{"id":"about-playbook","title":"About this Playbook","description":"This Playbook provides step-by-step guidance about how to use the Data Platform, along with technical documentation about how the platform has been set up and decisions we\'ve made. The Playbook has several intended audiences, and each section will be relevant to some more than others:","sidebar":"docs"},"architecture-decisions/index":{"id":"architecture-decisions/index","title":"Introduction","description":"An Architectural Decision (AD) is a software design choice that addresses a functional or non-functional requirement","sidebar":"docs"},"architecture-decisions/records/do-not-connect-to-production-databases":{"id":"architecture-decisions/records/do-not-connect-to-production-databases","title":"Using Event Streaming to Ingest Data - ADR 012","description":"","sidebar":"docs"},"architecture-decisions/records/ingest-google-sheets-data":{"id":"architecture-decisions/records/ingest-google-sheets-data","title":"Ingest Google Sheets Data - ADR 002","description":"","sidebar":"docs"},"architecture-decisions/records/ingest-sql-flat-files":{"id":"architecture-decisions/records/ingest-sql-flat-files","title":"Ingest SQL flat files - ADR 006","description":"","sidebar":"docs"},"architecture-decisions/records/ingesting-data-from-apis":{"id":"architecture-decisions/records/ingesting-data-from-apis","title":"Ingesting data from APIs - ADR 009","description":"","sidebar":"docs"},"architecture-decisions/records/initial-extract-of-tenure-data":{"id":"architecture-decisions/records/initial-extract-of-tenure-data","title":"Initial Extract of Tenure Data  - ADR 014","description":"","sidebar":"docs"},"architecture-decisions/records/move-staging-to-pre-production":{"id":"architecture-decisions/records/move-staging-to-pre-production","title":"Move Staging to Pre-Production - ADR 012","description":"","sidebar":"docs"},"architecture-decisions/records/partition-strategy":{"id":"architecture-decisions/records/partition-strategy","title":"Partition Strategy - ADR 004","description":"","sidebar":"docs"},"architecture-decisions/records/production-data-in-staging":{"id":"architecture-decisions/records/production-data-in-staging","title":"Production Data in Staging - ADR 008","description":"","sidebar":"docs"},"architecture-decisions/records/record-architecture-decisions":{"id":"architecture-decisions/records/record-architecture-decisions","title":"Record architecture decisions - ADR 001","description":"","sidebar":"docs"},"architecture-decisions/records/recovered-data":{"id":"architecture-decisions/records/recovered-data","title":"Recovered Data - ADR 005","description":"","sidebar":"docs"},"architecture-decisions/records/role-based-access-control":{"id":"architecture-decisions/records/role-based-access-control","title":"Role-Based Access Control - ADR 003","description":"","sidebar":"docs"},"architecture-decisions/records/sftp-to-s3-lambda":{"id":"architecture-decisions/records/sftp-to-s3-lambda","title":"Copy Liberator data from sftp to s3 - ADR 007","description":"Retrieve daily zip file from SFTP server and upload to S3 (landing zone bucket)","sidebar":"docs"},"architecture-decisions/records/spatial-data-processing":{"id":"architecture-decisions/records/spatial-data-processing","title":"Spatial Data Processing - ADR 015","description":"","sidebar":"docs"},"architecture-decisions/records/using-datahub-as-a-data-catalogue":{"id":"architecture-decisions/records/using-datahub-as-a-data-catalogue","title":"Using DataHub as a Data Catalogue - ADR 011","description":"","sidebar":"docs"},"architecture-decisions/records/using-event-streaming-to-ingest-data":{"id":"architecture-decisions/records/using-event-streaming-to-ingest-data","title":"Using Event Streaming to Ingest Data - ADR 013","description":"","sidebar":"docs"},"architecture-decisions/records/using-pytest-for-verifying-pyspark-transformations":{"id":"architecture-decisions/records/using-pytest-for-verifying-pyspark-transformations","title":"Using pytest for verifying PySpark transformations - ADR 010","description":"","sidebar":"docs"},"architecture-decisions/templates/template":{"id":"architecture-decisions/templates/template","title":"TITLE","description":""},"archived-articles/import-files-from-google-to-S3":{"id":"archived-articles/import-files-from-google-to-S3","title":"Import files from google to s3","description":"Import files from google to s3 description"},"dap-airflow/introduction":{"id":"dap-airflow/introduction","title":"\ud83d\udcdaIntroduction","description":"The DAP\u21e8flow guide for data analysts and engineers, for developing and deploying Airflow DAGs, running data pipelines in the Data Analytics Platform (DAP).","sidebar":"docs"},"dap-airflow/onboarding/access-my-Amazon-Athena-database":{"id":"dap-airflow/onboarding/access-my-Amazon-Athena-database","title":"Amazon Athena","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/access-my-current-service-data":{"id":"dap-airflow/onboarding/access-my-current-service-data","title":"My current service data","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/access-my-service-data-history":{"id":"dap-airflow/onboarding/access-my-service-data-history","title":"My service data history","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/access-the-AWS-Management-Console":{"id":"dap-airflow/onboarding/access-the-AWS-Management-Console","title":"AWS Console access","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/access-the-AWS-region":{"id":"dap-airflow/onboarding/access-the-AWS-region","title":"AWS region","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/begin":{"id":"dap-airflow/onboarding/begin","title":"Begin here","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/github-access":{"id":"dap-airflow/onboarding/github-access","title":"GitHub access","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/github-branch":{"id":"dap-airflow/onboarding/github-branch","title":"GitHub branching","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/github-commit-transform":{"id":"dap-airflow/onboarding/github-commit-transform","title":"Committing transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/github-pull-request":{"id":"dap-airflow/onboarding/github-pull-request","title":"GitHub pull requests","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/prototype-legacy-transforms":{"id":"dap-airflow/onboarding/prototype-legacy-transforms","title":"Prototype legacy transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/prototype-simple-transforms":{"id":"dap-airflow/onboarding/prototype-simple-transforms","title":"Prototype simple transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/query-my-service-data":{"id":"dap-airflow/onboarding/query-my-service-data","title":"Query my service data","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/onboarding/welcome":{"id":"dap-airflow/onboarding/welcome","title":"Welcome!","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/access-my-Amazon-Athena-database":{"id":"dap-airflow/parking/access-my-Amazon-Athena-database","title":"Amazon Athena","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/access-my-current-service-data":{"id":"dap-airflow/parking/access-my-current-service-data","title":"My current service data","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/access-my-service-data-history":{"id":"dap-airflow/parking/access-my-service-data-history","title":"My service data history","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/access-the-AWS-Management-Console":{"id":"dap-airflow/parking/access-the-AWS-Management-Console","title":"AWS Console access","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/access-the-AWS-region":{"id":"dap-airflow/parking/access-the-AWS-region","title":"AWS region","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/appendix-github-pull-request":{"id":"dap-airflow/parking/appendix-github-pull-request","title":"Appendix - GitHub pull requests","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration."},"dap-airflow/parking/appendix-migrating-transforms":{"id":"dap-airflow/parking/appendix-migrating-transforms","title":"Appendix - Migrating transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration."},"dap-airflow/parking/appendix-prototype-simple-transforms":{"id":"dap-airflow/parking/appendix-prototype-simple-transforms","title":"Appendix - Prototype simple transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration."},"dap-airflow/parking/begin":{"id":"dap-airflow/parking/begin","title":"Begin here","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/github-access":{"id":"dap-airflow/parking/github-access","title":"GitHub access","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/github-branch":{"id":"dap-airflow/parking/github-branch","title":"GitHub branching","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/github-commit-transform":{"id":"dap-airflow/parking/github-commit-transform","title":"Committing transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/github-orchestrate-transform":{"id":"dap-airflow/parking/github-orchestrate-transform","title":"Orchestrating transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/github-pull-request":{"id":"dap-airflow/parking/github-pull-request","title":"GitHub pull requests","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/migrating-transforms":{"id":"dap-airflow/parking/migrating-transforms","title":"Migrating transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/prototype-simple-transforms":{"id":"dap-airflow/parking/prototype-simple-transforms","title":"Prototype simple transforms","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/query-my-service-data":{"id":"dap-airflow/parking/query-my-service-data","title":"Query my service data","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/parking/welcome":{"id":"dap-airflow/parking/welcome","title":"Welcome!","description":"Onboarding data analysts and engineers to DAP\u21e8flow, the Data Analytics Platform Airflow integration.","sidebar":"docs"},"dap-airflow/ux":{"id":"dap-airflow/ux","title":"\ud83d\udcdaUX","description":"The DAP\u21e8flow guide for data analysts and engineers, for developing and deploying Airflow DAGs, running data pipelines in the Data Analytics Platform (DAP).","sidebar":"docs"},"dictionary/boundary":{"id":"dictionary/boundary","title":"Boundary","description":"describes the edge of the LBH area of responsibility"},"dictionary/person":{"id":"dictionary/person","title":"Person","description":"Someone belonging to a household or living in a property in Hackney"},"dictionary/property":{"id":"dictionary/property","title":"Property","description":"land and buildings in Hackney"},"dictionary/resident":{"id":"dictionary/resident","title":"Resident","description":"Someone who lives in Hackney"},"dictionary/service":{"id":"dictionary/service","title":"Service","description":"A service that is provided by LBH"},"docs/academy-ingestion":{"id":"docs/academy-ingestion","title":"Ingesting Academy data onto the Data Platform","description":"Overview of how Academy data is ingested onto the Data Platform from MS SQL databases and distributed to Housing Benefits & Needs and Revenues Departments","sidebar":"docs"},"docs/alloy-ingestion":{"id":"docs/alloy-ingestion","title":"Alloy data ingestion","description":"Description of the ingestion and refinement pipeline for Alloy Environmental Services data","sidebar":"docs"},"docs/auto-adjusting-aws-budget":{"id":"docs/auto-adjusting-aws-budget","title":"Auto-adjusting AWS Budget Alerts","description":"Overview of the Auto-adjusting Budget Alerts","sidebar":"docs"},"docs/backdated-liberator-ingestion":{"id":"docs/backdated-liberator-ingestion","title":"Backdated Liberator data ingestion","description":"Description of the backdated ingestion process for Liberator data","sidebar":"docs"},"docs/CD-process":{"id":"docs/CD-process","title":"CD Process","description":"Explaination of the CD process for the Data Platform","sidebar":"docs"},"docs/CI-process":{"id":"docs/CI-process","title":"CI Process","description":"Explaination of the CI process for the Data Platform","sidebar":"docs"},"docs/exporting-snapshot-to-landing-zone":{"id":"docs/exporting-snapshot-to-landing-zone","title":"Exporting database snapshots to the Data Platform Landing Zone","description":"Overview of how db snapshots are exported to the Data Platform Landing Zone","sidebar":"docs"},"docs/import-external-files-to-landing-zone":{"id":"docs/import-external-files-to-landing-zone","title":"Importing external files to the Data Platform Landing Zone","description":"Overview of how files from external suppliers are imported to the Data Platform Landing Zone","sidebar":"docs"},"docs/import-spreadsheet-from-g-drive":{"id":"docs/import-spreadsheet-from-g-drive","title":"Import spreadsheets from G Drive","description":"Overview of how data is imported from spreadsheets that are stored in G drive","sidebar":"docs"},"docs/liberator-ingestion":{"id":"docs/liberator-ingestion","title":"Liberator data ingestion","description":"Description of the ingestion process for Liberator data","sidebar":"docs"},"docs/redshift":{"id":"docs/redshift","title":"Redshift - Creating users, databases and exposing data from Glue","description":"","sidebar":"docs"},"docs/ringgo-ingestion":{"id":"docs/ringgo-ingestion","title":"RingGo data ingestion","description":"Description of the ingestion process for RingGo data","sidebar":"docs"},"docs/tascomi-ingestion":{"id":"docs/tascomi-ingestion","title":"Tascomi data ingestion","description":"Description of the ingestion and refinement pipeline for Tascomi planning data","sidebar":"docs"},"docs/vpc-peering-connection-dataplatform-and-production-apis-account":{"id":"docs/vpc-peering-connection-dataplatform-and-production-apis-account","title":"VPC Peering Connection between Data Platform and Production APIs AWS accounts","description":"Overview of how the VPC Peering Connection and its purpose","sidebar":"docs"},"environments":{"id":"environments","title":"Environments","description":"The platform has the following 3 environments:","sidebar":"docs"},"glossary":{"id":"glossary","title":"Glossary","description":"A Table of terms of Terms and Tools used by the Data Platform","sidebar":"docs"},"introduction":{"id":"introduction","title":"About the Data Platform","description":"What is a data platform?","sidebar":"docs"},"playbook/elements-of-the-platform/data-catalogue":{"id":"playbook/elements-of-the-platform/data-catalogue","title":"Data Catalogue","description":"What is a data catalogue?","sidebar":"docs"},"playbook/elements-of-the-platform/data-lake":{"id":"playbook/elements-of-the-platform/data-lake","title":"Data Lake","description":"This is an overview of the data lake, its responsibilities and how data moves through the zones within the data lake","sidebar":"docs"},"playbook/elements-of-the-platform/data-warehouse":{"id":"playbook/elements-of-the-platform/data-warehouse","title":"Data Warehouse","description":"This is an overview of the data warehouse, its responsibilities and how data is served from within the Data Platform","sidebar":"docs"},"playbook/exporting-data/save-glue-catalog-to-google-sheet":{"id":"playbook/exporting-data/save-glue-catalog-to-google-sheet","title":"Export data catalog table or view to Google Sheets","description":"Objective","sidebar":"docs"},"playbook/finding-data/data-catalogue":{"id":"playbook/finding-data/data-catalogue","title":"Using the data catalogue","description":"How to use the data catalogue","sidebar":"docs"},"playbook/getting-access-to-data/index":{"id":"playbook/getting-access-to-data/index","title":"Introduction","description":"Customisable field..","sidebar":"docs"},"playbook/getting-access-to-data/Tableau-to-redshift":{"id":"playbook/getting-access-to-data/Tableau-to-redshift","title":"Connecting to the Data Platform from Tableau","description":"How to connect to the Data Platform from Tableau Online using Redshift or Athena","sidebar":"docs"},"playbook/getting-set-up/index":{"id":"playbook/getting-set-up/index","title":"Introduction","description":"Engineer and Analyst Prerequisites","sidebar":"docs"},"playbook/getting-set-up/local-pyspark-environment":{"id":"playbook/getting-set-up/local-pyspark-environment","title":"Getting started with the local PySpark environment","description":"Setting up a PySpark environment on a local machine and running Data Platform scripts.","sidebar":"docs"},"playbook/getting-set-up/notebook-setup":{"id":"playbook/getting-set-up/notebook-setup","title":"Local Notebook Environment Setup","description":"Local Notebook Environment Setup","sidebar":"docs"},"playbook/getting-set-up/onboarding-new-departments-to-the-platform":{"id":"playbook/getting-set-up/onboarding-new-departments-to-the-platform","title":"Onboarding new departments to the platform","description":"How to add a new Google group for a department.","sidebar":"docs"},"playbook/getting-set-up/onboarding-new-users-to-the-platform":{"id":"playbook/getting-set-up/onboarding-new-users-to-the-platform","title":"Onboarding new users to the platform","description":"How to add users to a Google group","sidebar":"docs"},"playbook/getting-set-up/using-github":{"id":"playbook/getting-set-up/using-github","title":"Using GitHub","description":"A guide on how to carry out common tasks in GitHub","sidebar":"docs"},"playbook/ingesting-data/creating-a-lambda-function-step-by-step":{"id":"playbook/ingesting-data/creating-a-lambda-function-step-by-step","title":"How to create a Lambda function for data ingestion on the Data Analytics Platform","description":"Ingesting data using AWS Lambda [step-by-step]","sidebar":"docs"},"playbook/ingesting-data/database-ingestion":{"id":"playbook/ingesting-data/database-ingestion","title":"Ingesting data from databases into the Data Platform","description":"Ingesting database tables into the Data Platform using a JDBC Connection","sidebar":"docs"},"playbook/ingesting-data/event-streaming":{"id":"playbook/ingesting-data/event-streaming","title":"Ingesting new data entities via event streaming","description":"Setting up a new Kafka topic to streaming events to from a new data entity","sidebar":"docs"},"playbook/ingesting-data/google-sheets-import":{"id":"playbook/ingesting-data/google-sheets-import","title":"Ingesting data from Google Sheets","description":"Objective","sidebar":"docs"},"playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive":{"id":"playbook/ingesting-data/ingest-spreadsheet-files-from-g-drive","title":"Ingest spreadsheet files from G Drive","description":"Ingest spreadsheet files from G Drive description","sidebar":"docs"},"playbook/ingesting-data/ingesting-api-data":{"id":"playbook/ingesting-data/ingesting-api-data","title":"Ingesting data from an API to the Data Platform","description":"Ingesting API data into the Data Platform using an AWS Lambda function","sidebar":"docs"},"playbook/ingesting-data/ingesting-dynamo-db-tables":{"id":"playbook/ingesting-data/ingesting-dynamo-db-tables","title":"Ingesting Dynamo DB tables into the Landing Zone","description":"Ingesting tables from a Dynamo DB instance into the Data Platform landing zone","sidebar":"docs"},"playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone":{"id":"playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone","title":"Ingesting RDS snapshot into the Data Platform Landing Zone","description":"Ingesting a snapshot of an RDS instance into the DataPlatform landing zone","sidebar":"docs"},"playbook/ingesting-data/manual-ingest-of-csv-files":{"id":"playbook/ingesting-data/manual-ingest-of-csv-files","title":"Ingest manually uploaded csv files","description":"Ingest data from csv files","sidebar":"docs"},"playbook/ingesting-data/production-to-pre-production-sync":{"id":"playbook/ingesting-data/production-to-pre-production-sync","title":"Production to pre-production data sync","description":"Overview of how data is copied from production to pre-production","sidebar":"docs"},"playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script":{"id":"playbook/ingesting-data/tips-on-how-to-write-an-API-Lambda-script","title":"Tips on writing an API Ingestion script for AWS Lambda","description":"Recommendations to write an API ingestion script for a Lambda in the Data Platform","sidebar":"docs"},"playbook/ingesting-data/using-watermarks-to-record-job-states":{"id":"playbook/ingesting-data/using-watermarks-to-record-job-states","title":"Using Watermarks to Record AWS GLue Job States Between Runs","description":"Use of the watermarks class for recording Glue job states between runs","sidebar":"docs"},"playbook/ingesting-data/what-data-are-we-ingesting":{"id":"playbook/ingesting-data/what-data-are-we-ingesting","title":"Types of data and ingestion process","description":"Due to the variety of data sources we have had to develop several different ingestion methods. These methods and the data being ingested are detailed in this section","sidebar":"docs"},"playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio":{"id":"playbook/querying-and-analysing-data/connecting-to-redshift-from-data-studio","title":"Connecting to the Redshift cluster from Google Data Studio","description":"Connect to the Redshift cluster from Google Data Studio","sidebar":"docs"},"playbook/querying-and-analysing-data/create_a_data_extract_in_GDS":{"id":"playbook/querying-and-analysing-data/create_a_data_extract_in_GDS","title":"Create a data extract in Google Data Studio","description":"Create an extract to optimise dashboard performance","sidebar":"docs"},"playbook/querying-and-analysing-data/geospatial-enrichments":{"id":"playbook/querying-and-analysing-data/geospatial-enrichments","title":"Geospatial enrichment","description":"How to perform geospatial enrichment on data held in the data platform","sidebar":"docs"},"playbook/querying-and-analysing-data/querying-data-using-sql":{"id":"playbook/querying-and-analysing-data/querying-data-using-sql","title":"Querying the Data Platform using SQL within AWS Athena","description":"AWS Athena to query data in S3","sidebar":"docs"},"playbook/querying-and-analysing-data/time-series-analysis/basic_helpers":{"id":"playbook/querying-and-analysing-data/time-series-analysis/basic_helpers","title":"2. Basic Time Series helpers","description":"Generally useful Time Series Helpers","sidebar":"docs"},"playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets":{"id":"playbook/querying-and-analysing-data/time-series-analysis/exponential_smoothing_ets","title":"Exponential Smoothing ETS","description":"Forecast using Exponential Smoothing","sidebar":"docs"},"playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets":{"id":"playbook/querying-and-analysing-data/time-series-analysis/holt_winters_ets","title":"Holt Winters ETS","description":"Forecast using Holt Winters ETS","sidebar":"docs"},"playbook/querying-and-analysing-data/time-series-analysis/introduction":{"id":"playbook/querying-and-analysing-data/time-series-analysis/introduction","title":"1. Introduction to Time Series Helpers","description":"Introduction to Time Series Helpers","sidebar":"docs"},"playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example":{"id":"playbook/querying-and-analysing-data/time-series-analysis/step_by_step_example","title":"3. Step by Step Guide to Forecasting","description":"Step by Step Guide with examples to follow along with","sidebar":"docs"},"playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide":{"id":"playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide","title":"Guide to testing data quality in Glue Jobs","description":"A guide to continuous data quality testing in Glue Jobs","sidebar":"docs"},"playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide":{"id":"playbook/transforming-data/guides-to-testing-in-the-platform/unit-testing-guide","title":"Guide to unit testing on the Data Platform","description":"A beginners guide to testing on the data platform","sidebar":"docs"},"playbook/transforming-data/using-aws-glue/deploy-glue-jobs":{"id":"playbook/transforming-data/using-aws-glue/deploy-glue-jobs","title":"Deploying Glue jobs to the Data Platform","description":"Creating Glue jobs in terraform","sidebar":"docs"},"playbook/transforming-data/using-aws-glue/optimizing-glue-jobs":{"id":"playbook/transforming-data/using-aws-glue/optimizing-glue-jobs","title":"Optimizing Glue jobs","description":"Elements for optimizing glue jobs","sidebar":"docs"},"playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs":{"id":"playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs","title":"Scheduling Liberator Glue Jobs","description":"Schedule a glue job to run when new liberator data is added into the platform","sidebar":"docs"},"playbook/transforming-data/using-aws-glue/using-glue-studio":{"id":"playbook/transforming-data/using-aws-glue/using-glue-studio","title":"Using Glue Studio","description":"Using AWS Glue Studio to create ETL processes.","sidebar":"docs"},"playbook/transforming-data/using-aws-glue/using-sagemaker":{"id":"playbook/transforming-data/using-aws-glue/using-sagemaker","title":"Prototyping glue jobs in a notebook","description":"Prototyping transformation scripts using a Jupyter Notebook","sidebar":"docs"},"release-notes":{"id":"release-notes","title":"Release Notes","description":"Target Audience"},"roles":{"id":"roles","title":"Roles","description":"There are currently four tiers of role within the data platform project, and they are as follows:","sidebar":"docs"},"spikes/amundsen-deployment":{"id":"spikes/amundsen-deployment","title":"Amundsen deployment","description":"Review amundsen as a potential solution for a data catalogue","sidebar":"docs"},"spikes/data-quality-testing":{"id":"spikes/data-quality-testing","title":"Data Quality Testing","description":"Testing data quality from Glue jobs","sidebar":"docs"},"spikes/datahub-deployment":{"id":"spikes/datahub-deployment","title":"Datahub deployment","description":"Review datahub as a potential solution for a data catalogue","sidebar":"docs"},"spikes/mssql-ingestion":{"id":"spikes/mssql-ingestion","title":"Ingesting data from MSSQL database","description":"Investigate creating a reusable process for ingesting data from MS SQL and other types of databases","sidebar":"docs"},"spikes/qlik-integration":{"id":"spikes/qlik-integration","title":"Qlik Integration","description":"","sidebar":"docs"},"spikes/sagemaker":{"id":"spikes/sagemaker","title":"Sagemaker","description":"Investigating whether using AWS sagemaker with AWS glue development endpoints is a viable notebooking tool","sidebar":"docs"},"spikes/templates/example":{"id":"spikes/templates/example","title":"Spike: Full-text address search with fuzzy matching.","description":"Postgres Tools vs Elasticsearch"},"spikes/templates/template":{"id":"spikes/templates/template","title":"TITLE","description":""},"training-modules/module-0":{"id":"training-modules/module-0","title":"Getting started with training","description":"Training Module: Getting started with training","sidebar":"docs"},"training-modules/module-1":{"id":"training-modules/module-1","title":"Ingesting data from Google Sheets","description":"Training Module: Ingesting data from Google Sheets into the Data Platform raw zone","sidebar":"docs"},"training-modules/module-2":{"id":"training-modules/module-2","title":"Transforming data to refined zone using Sagemaker","description":"Training module: Transforming data to the refined zone using Sagemaker","sidebar":"docs"},"training-modules/module-3":{"id":"training-modules/module-3","title":"Deploying a job in AWS Glue","description":"Training module: Deploying a job in AWS Glue","sidebar":"docs"},"training-modules/Qlik/qlik-module-1":{"id":"training-modules/Qlik/qlik-module-1","title":"Module 1 - Introduction to Qlik","description":"Qlik Training Module 1","sidebar":"docs"},"training-modules/Qlik/qlik-module-2":{"id":"training-modules/Qlik/qlik-module-2","title":"Module 2 - Developing a simple dashboard","description":"Qlik Training Module 2","sidebar":"docs"},"workshop/aws_glue_studio_parking":{"id":"workshop/aws_glue_studio_parking","title":"Glue Studio workshop with Parking Analysts","description":"","sidebar":"docs"},"zones":{"id":"zones","title":"Zones","description":"The Platform has 4 data zones, as data is moved from the landing or raw zones to the trusted zone it will become:","sidebar":"docs"}}}}')}}]);