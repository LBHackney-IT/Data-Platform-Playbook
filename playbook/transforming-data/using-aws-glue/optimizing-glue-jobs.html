<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-playbook/transforming-data/using-aws-glue/optimizing-glue-jobs" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">Optimizing Glue jobs | Hackney Data Platform Playbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://playbook.hackney.gov.uk/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Optimizing Glue jobs | Hackney Data Platform Playbook"><meta data-rh="true" name="description" content="Elements for optimizing glue jobs"><meta data-rh="true" property="og:description" content="Elements for optimizing glue jobs"><link data-rh="true" rel="icon" href="/Data-Platform-Playbook/img/favicon.png"><link data-rh="true" rel="canonical" href="https://playbook.hackney.gov.uk/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs"><link data-rh="true" rel="alternate" href="https://playbook.hackney.gov.uk/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs" hreflang="en"><link data-rh="true" rel="alternate" href="https://playbook.hackney.gov.uk/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://KNMFHOJ4X2-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="Hackney Data Platform Playbook" href="/Data-Platform-Playbook/opensearch.xml"><link rel="stylesheet" href="/Data-Platform-Playbook/assets/css/styles.2e3b48f9.css">
<script src="/Data-Platform-Playbook/assets/js/runtime~main.d0a161b4.js" defer="defer"></script>
<script src="/Data-Platform-Playbook/assets/js/main.2fe36f58.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Data-Platform-Playbook/"><div class="navbar__logo"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Data Platform Playbook</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/LBHackney-IT/data-platform-playbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/">About</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Data-Platform-Playbook/playbook/getting-set-up">Playbook</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/getting-set-up">Getting set up on the platform</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/elements-of-the-platform/data-catalogue">Elements of the platform</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/finding-data/data-catalogue">Finding data on the platform</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/getting-access-to-data/Tableau-to-redshift">Getting access to data</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/what-data-are-we-ingesting">Ingesting data</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide">Transforming data</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide">Guides to testing in the platform</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio">Using AWS Glue</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio">Using Glue Studio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs">Deploying Glue jobs to the Data Platform</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker">Prototyping glue jobs in a notebook</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs">Optimizing Glue jobs</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs">Practical examples</a></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Data-Platform-Playbook/playbook/querying-and-analysing-data/time-series-analysis/introduction">Querying and analysing data</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/training-modules/module-0">Training Modules</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/docs/CD-process">Technical Documentation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/dap-airflow/introduction">DAP⇨flow</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/architecture-decisions">Architecture Decision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Data-Platform-Playbook/spikes/amundsen-deployment">Spikes</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/glossary">Glossary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/roles">Roles</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Data-Platform-Playbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Playbook</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Transforming data</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Using AWS Glue</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Optimizing Glue jobs</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><p>This article proposes a few principles to follow so that Glue jobs don’t run unnecessarily slowly.</p>
<header><h1>Making sure the job processes the minimum amount of data</h1></header>
<p>Most of the time, we only are interested in the latest partition of the source data.
When working from the <em>Trusted zone</em>, most of the time, only the latest data is available so there is nothing to do. But when working from the refined or the raw zone, historical partitions exist that we need to discard. This section describes several ways to do this.</p>
<p>As shown on the picture below, the typical job first loads some data from S3 using <code>Execution_context.get_dataframe</code> or <code>glueContext.create_dynamic_frame.from_catalog</code>, and then filters it down to only keep the latest records using <code>df.get_latest_partition</code> or
<code>df.get_latest_partition_optimized</code>.</p>
<p><img decoding="async" loading="lazy" alt="Typical steps when loading and processing data from S3" src="/Data-Platform-Playbook/assets/images/loading-processing-steps-291c3e1485892f42ac9a224377dc3611.png" width="2170" height="1216" class="img_ev3q"></p>
<p>There are opportunities to filter data at both stages: before creating the dataframe and afterwards. Options are described below.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="filtering-data-before-creating-the-dataframe">Filtering data before creating the dataframe<a href="#filtering-data-before-creating-the-dataframe" class="hash-link" aria-label="Direct link to Filtering data before creating the dataframe" title="Direct link to Filtering data before creating the dataframe">​</a></h2>
<p>In this section we’ll explore job bookmarks and pushdown predicates.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="job-bookmarks">Job bookmarks<a href="#job-bookmarks" class="hash-link" aria-label="Direct link to Job bookmarks" title="Direct link to Job bookmarks">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-it-works">How it works<a href="#how-it-works" class="hash-link" aria-label="Direct link to How it works" title="Direct link to How it works">​</a></h3>
<p>Job Bookmark is a Glue feature that operates at file level. It completely ignores partitions.
With Bookmark on, the Glue job will only load files that have changed or have been created in the source bucket/folder since the last successful run. It will result in a smaller dataframe.</p>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="Loading and processing data from S3 using Glue job bookmarks" src="/Data-Platform-Playbook/assets/images/loading-processing-steps-with-bookmarks-828cae06cd5f21f76a6a3875b82d7a94.png" width="2196" height="1214" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><em>In this example, since the last job run, one additional file has been created on the 4/10/2022 and 2 on the 5/10/2022. These 3 files are in different partitions but the bookmarks ignores this fact. The 3 files will get loaded into the same dataframe and processed in the next job run.</em></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pros">Pros<a href="#pros" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h3>
<ul>
<li>Glue built-in feature.</li>
<li>Rewind, reset, disable the bookmark in the Glue console without touching the script.</li>
<li>The bookmark does not rely on crawlers, partitions or catalogue.</li>
<li>Fine grained filtering: if a new file comes in the middle of the day while others have been processed a few hours earlier, you can run your job and only process the new one. You cannot do that if filtering at partition level.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cons">Cons<a href="#cons" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h3>
<ul>
<li>If an old file changes in the source bucket, it will be processed, whatever partition it is in. To prevent this, additional precautions may be taken (extra filtering using SQL or pushdown predicate).</li>
<li>Job bookmarks are not very transparent. It is difficult to know what was the last file processed.</li>
<li>Users may not know how, or not have permissions to, reset or rewind the bookmark (it used to be only accessible in the legacy pages).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scenarios-when-not-to-use-it">Scenarios when not to use it<a href="#scenarios-when-not-to-use-it" class="hash-link" aria-label="Direct link to Scenarios when not to use it" title="Direct link to Scenarios when not to use it">​</a></h3>
<p>Bookmarks are not very convenient for a test job that is meant to process several times the same data. Not great if you have several data sources with different filtering requirements: you can choose to use the bookmark or not for each source (using the transformation_ctx in the loading block), but you cannot rewind or reset the bookmark for only one source.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-it-in-a-job">How to use it in a job<a href="#how-to-use-it-in-a-job" class="hash-link" aria-label="Direct link to How to use it in a job" title="Direct link to How to use it in a job">​</a></h3>
<p>Enabling bookmarks requires 2 steps.</p>
<ol>
<li>In the job parameters or in Terraform: Use the standard job parameter <code>bookmark=enable</code> (It is disabled by default in Glue console and in our Job terraform module).</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Enabling job bookmarks in Terraform" src="/Data-Platform-Playbook/assets/images/enabling-bookmark-in-terraform-9b409b4bacc9f37e00d97c0c49581d99.png" width="2272" height="1306" class="img_ev3q"></p>
<ol start="2">
<li>In the job script: for incremental data sources that need bookmarking, set the <code>transformation_ctx</code> to a unique string value when creating the data frame. For data sources that don&#x27;t change and need to be processed each time, don&#x27;t set a <code>transformation_ctx</code> and the bookmark won&#x27;t apply.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Setting the transformation_ctx for job bookmarks" src="/Data-Platform-Playbook/assets/images/setting-transformation-ctx-for-job-bookmarks-b3dd325cdaf4ba47054e2ec95ebf2b1c.png" width="1066" height="230" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="external-doc-about-job-bookmarks">External doc about job bookmarks<a href="#external-doc-about-job-bookmarks" class="hash-link" aria-label="Direct link to External doc about job bookmarks" title="Direct link to External doc about job bookmarks">​</a></h3>
<p><a href="https://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html</a>
<a href="https://medium.com/analytics-vidhya/implementing-glue-etl-job-with-job-bookmarks-b76a8ba38dc8" target="_blank" rel="noopener noreferrer">https://medium.com/analytics-vidhya/implementing-glue-etl-job-with-job-bookmarks-b76a8ba38dc8</a>
Datasets with different update cycles: <a href="https://aws.amazon.com/blogs/big-data/process-data-with-varying-data-ingestion-frequencies-using-aws-glue-job-bookmarks/" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/blogs/big-data/process-data-with-varying-data-ingestion-frequencies-using-aws-glue-job-bookmarks/</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="pushdown-predicates">Pushdown predicates<a href="#pushdown-predicates" class="hash-link" aria-label="Direct link to Pushdown predicates" title="Direct link to Pushdown predicates">​</a></h2>
<p>When using a pushdown predicate, Glue will only load partitions (S3 folders) meeting the predicate.
This example assumes import_date is a partition key:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">df = glueContext.create_dynamic_frame.from_catalog(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            name_space=database_name,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            table_name=table_name,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            push_down_predicate = &quot;import_date==&#x27;20221001&#x27;&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This statement results in a smaller dataframe.</p>
<p>How to create the pushdown predicate in a script? Using the DP helpers, there are 2 ways to set the date dynamically:</p>
<ul>
<li>Using the current date and adding a few days buffer before this date (i.e. loading everything in the last n days)</li>
<li>Using the max partition date by checking the Glue catalogue (i.e. loading the data with the max value for partition date, whatever its age is)</li>
<li>Using the latest written partition by checking creation timestamps in the Glue catalogue (i.e. loading the latest written data, whatever its age is)</li>
</ul>
<p>These 3 approaches and their pros/cons are described below.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pushdown-predicate-based-on-the-current-date--a-few-days-buffer">Pushdown predicate based on the current date + a few days buffer<a href="#pushdown-predicate-based-on-the-current-date--a-few-days-buffer" class="hash-link" aria-label="Direct link to Pushdown predicate based on the current date + a few days buffer" title="Direct link to Pushdown predicate based on the current date + a few days buffer">​</a></h3>
<p>This methos loads the current day&#x27;s partition + the n previous ones.</p>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="Loading and processing data from S3 using a pushdown predicate with a 1 day buffer" src="/Data-Platform-Playbook/assets/images/loading-processing-steps-with-pushdown-predicate-buffer-d9559136d9d3a5a8a67037f874491d14.png" width="2398" height="1352" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><em>In this example, we have 3 partitions for 3 different import_dates. The job runs on the 5/10/2022. Because of the pushdown predicate wih buffer, it will load and process data from the same day&#x27;s partition, + 1 previous day.</em></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pros-1">Pros<a href="#pros-1" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h4>
<p>This approach gives you a security buffer when you&#x27;re not sure which is the latest non-empty partition. For instance, if a job runs every day except from the weekend, a 2 days buffer will ensure you always load some data, even on a Monday morning. A 1 day buffer is also useful if you’re not sure if the source data is produced before or after midnight.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cons-1">Cons<a href="#cons-1" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h4>
<ul>
<li>This method can be expensive (i.e. load more data than needed) if you want a large buffer.</li>
<li>You can miss data if there is a longer gap than expected in the catalogue</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scenarios-when-not-to-use-it-1">Scenarios when not to use it<a href="#scenarios-when-not-to-use-it-1" class="hash-link" aria-label="Direct link to Scenarios when not to use it" title="Direct link to Scenarios when not to use it">​</a></h4>
<p>This is not suitable if the data source comes very irregularly, because you may not know which size of buffer to use.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-it-in-a-job-1">How to use it in a job<a href="#how-to-use-it-in-a-job-1" class="hash-link" aria-label="Direct link to How to use it in a job" title="Direct link to How to use it in a job">​</a></h4>
<ol>
<li>Import the helper function called <code>create_pushdown_predicate</code>.</li>
<li>Call the <code>create_pushdown_predicate()</code> method in the <code>push_down_predicate</code> option of the <code>createDataFrame</code> block. Pass the name of the partition column as the first argument and the number of days before the current date as the second argument. For instance, to load the data written in the last 7 days, write:</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Write a pushdown predicate with a 7 days buffer" src="/Data-Platform-Playbook/assets/images/write-pushdown-predicate-with-7-days-buffer-7bdd7528f44ca8c93e92a63fa8cc0f74.png" width="1742" height="218" class="img_ev3q"></p>
<p><em>Warning</em>: a buffer size of 0 means that you’re loading the full dataset.</p>
<ol start="3">
<li>Later in your script, you can use <code>get_latest_partitions()</code> on the resulting dataframe to only keep one day&#x27;s worth of data.</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pushdown-predicate-based-on-the-max-value-of-date-partition-registered-in-the-glue-catalogue">Pushdown predicate based on the max value of date partition registered in the Glue catalogue<a href="#pushdown-predicate-based-on-the-max-value-of-date-partition-registered-in-the-glue-catalogue" class="hash-link" aria-label="Direct link to Pushdown predicate based on the max value of date partition registered in the Glue catalogue" title="Direct link to Pushdown predicate based on the max value of date partition registered in the Glue catalogue">​</a></h3>
<p>With this method, a helper queries the Glue catalogue with boto3 to get the max partition value as a string, i.e. &#x27;20221005&#x27; (this string can also be returned). It then creates a pushdown predicate to load only this partition.</p>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="Loading and processing data from S3 using a pushdown predicate fetching the max partition date value from the Glue catalogue" src="/Data-Platform-Playbook/assets/images/loading-processing-steps-with-pushdown-predicate-on-max-date-1a6a02454dbb939c067d1860d3bb8ee7.png" width="1250" height="696" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><em>In this example, we have 3 partitions for 3, 4, and 5/10/2022. The job runs on the 7/10/2022. The max import_date partition in the cataloque is &#x27;20221005&#x27;. The pushdown predicate will be based on this and the job will load and process this partition only.</em></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pros-2">Pros<a href="#pros-2" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h4>
<ul>
<li>This approach never loads more than one day’s worth of data, so it is cheap.</li>
<li>It works even if you have no idea when source data was last produced</li>
<li>You don&#x27;t need a GetLatestPartitions query after loading your dataframe</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cons-2">Cons<a href="#cons-2" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h4>
<ul>
<li>This approach assumes you have a date partitions with values in &#x27;yyyymmdd&#x27; format, and that you know the name of the partition key.</li>
<li>This approach relies on the Glue catalogue being up-to-date and not containing empty partitions. If data is deleted, we want the corresponding partition to be removed from the catalogue. If crawlers are used to update the catalogue, they must be set up with the non-standard option as below::</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Crawler option to delete empty partitions" src="/Data-Platform-Playbook/assets/images/crawler-option-to-delete-empty-partitions-60a0607a196bb39244aebcf3b4220cbc.png" width="1544" height="294" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scenarios-when-not-to-use-it-2">Scenarios when not to use it<a href="#scenarios-when-not-to-use-it-2" class="hash-link" aria-label="Direct link to Scenarios when not to use it" title="Direct link to Scenarios when not to use it">​</a></h4>
<p>This is not suitable if the catalogue contains deprecated partitions. Not suitable if you don&#x27;t have a date partition. For instance, it won&#x27;t support data with only import_year, import_month and import_day.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-it-in-a-job-2">How to use it in a job<a href="#how-to-use-it-in-a-job-2" class="hash-link" aria-label="Direct link to How to use it in a job" title="Direct link to How to use it in a job">​</a></h4>
<ol>
<li>Import the DP helper method <code>create_pushdown_predicate_for_max_date_partition_value</code></li>
<li>Call the method in the <code>push_down_predicate</code> option of the <code>createDataFrame</code> block (the example below uses the <code>execution_context</code> to create the data frame but the same can be achieved using <code>create_dynamic_frame.from_catalogue</code>)</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Write a pushdown predicate based on the max partition date from the Glue catalogue" src="/Data-Platform-Playbook/assets/images/how-to-use-pushdown-predicate-on-max-date-9866d7aead4c45f6a8d9c7f3e591f5ac.png" width="1178" height="192" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pushdown-predicate-based-on-the-latest-written-partition-registered-in-the-glue-catalogue">Pushdown predicate based on the latest written partition registered in the Glue catalogue<a href="#pushdown-predicate-based-on-the-latest-written-partition-registered-in-the-glue-catalogue" class="hash-link" aria-label="Direct link to Pushdown predicate based on the latest written partition registered in the Glue catalogue" title="Direct link to Pushdown predicate based on the latest written partition registered in the Glue catalogue">​</a></h3>
<p>With this method, a helper queries the Glue catalogue with boto3 to get the all the partitions creation timestamps. It then selected the latest one, get the partitions key-value pairs, and create a pushdown predicate with these.</p>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="Loading and processing data from S3 using a pushdown predicate fetching the latest written partition from the Glue catalogue" src="/Data-Platform-Playbook/assets/images/loading-processing-steps-with-pushdown-predicate-on-latest-written-0f923d98446fcf5eb0db68af2a2b75dc.png" width="1252" height="696" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><em>In this example, we have 3 partitions for 3, 4, and 5/10/2022 but they don&#x27;t have a date partition, only year/month/date. The job runs on the 7/10/2022. The helper will check the creation timestamps of partitons in the Glue catalogue. It will identify that the partition written on 05/10/2022 is the most recent one and that its partition values are 2022, 10 and 5. The pushdown predicate will be created based on these 3 values and the job will load and process this partition only.</em></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pros-3">Pros<a href="#pros-3" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h4>
<ul>
<li>This approach never loads more than one day’s worth of data, so it is cheap.</li>
<li>It works even if you have no idea when source data was last produced</li>
<li>You don&#x27;t need a GetLatestPartitions query after loading your dataframe</li>
<li>You don&#x27;t need to know the partition keys and they don&#x27;t need to have one in &#x27;yyyymmdd&#x27; format</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cons-3">Cons<a href="#cons-3" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h4>
<ul>
<li>If the partitions are more granular than a day (i.e. several a day) or less granular, you won&#x27;t get exactly one day of data</li>
<li>Like the previous one, this approach relies on the Glue catalogue being up-to-date and not containing empty partitions. If data is deleted, we want the corresponding partition to be removed from the catalogue. If crawlers are used to update the catalogue, they must be set up with the non-standard option as below:</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Crawler option to delete empty partitions" src="/Data-Platform-Playbook/assets/images/crawler-option-to-delete-empty-partitions-60a0607a196bb39244aebcf3b4220cbc.png" width="1544" height="294" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scenarios-when-not-to-use-it-3">Scenarios when not to use it<a href="#scenarios-when-not-to-use-it-3" class="hash-link" aria-label="Direct link to Scenarios when not to use it" title="Direct link to Scenarios when not to use it">​</a></h4>
<p>This is not suitable if the catalogue contains deprecated partitions. Not suitable if data is being written more than once a day and you do want to load a full day.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-it-in-a-job-3">How to use it in a job<a href="#how-to-use-it-in-a-job-3" class="hash-link" aria-label="Direct link to How to use it in a job" title="Direct link to How to use it in a job">​</a></h4>
<ol>
<li>Import the DP helper method <code>create_pushdown_predicate_for_latest_written_partition</code></li>
<li>Call the method in the <code>push_down_predicate</code> option of the <code>createDataFrame</code> block (the example below uses the <code>execution_context</code> to create the data frame but the same can be achieved using <code>create_dynamic_frame.from_catalogue</code>)</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Write a pushdown predicate based on the latest written partition from the Glue catalogue" src="/Data-Platform-Playbook/assets/images/how-to-use-pushdown-predicate-on-latest-written-partition-49feeae0557660601701d521d1cdc713.png" width="1047" height="140" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="external-documentation-about-pushdown-predicates">External documentation about pushdown predicates<a href="#external-documentation-about-pushdown-predicates" class="hash-link" aria-label="Direct link to External documentation about pushdown predicates" title="Direct link to External documentation about pushdown predicates">​</a></h3>
<p><a href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-partitions.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-partitions.html</a>
<a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/helpers/helpers.py" target="_blank" rel="noopener noreferrer">https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/helpers/helpers.py</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="filtering-data-after-creating-the-dataframe">Filtering data after creating the dataframe<a href="#filtering-data-after-creating-the-dataframe" class="hash-link" aria-label="Direct link to Filtering data after creating the dataframe" title="Direct link to Filtering data after creating the dataframe">​</a></h2>
<p>After you have loaded data into a dataframe, you can use a pySpark query that only keeps the latest day from all the loaded data.
This will work whatever approach you have used to create the dataframe. It does not rely on the Glue catalogue and on registered partitions, but only on the loaded data content. This method has been used in nearly every job in the early Data Platform.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pros-4">Pros<a href="#pros-4" class="hash-link" aria-label="Direct link to Pros" title="Direct link to Pros">​</a></h3>
<p>Certitude you only are processing one day’s worth of data</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cons-4">Cons<a href="#cons-4" class="hash-link" aria-label="Direct link to Cons" title="Direct link to Cons">​</a></h3>
<p>Can be very expensive if you have loaded many partitions in your dataframe.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-it-in-a-job-4">How to use it in a job<a href="#how-to-use-it-in-a-job-4" class="hash-link" aria-label="Direct link to How to use it in a job" title="Direct link to How to use it in a job">​</a></h3>
<ol>
<li>Import the helper function. Several versions of the helper exist:</li>
</ol>
<ul>
<li><code>get_latest_partitions</code> is the initial version, it uses a <code>where()</code> clause and the standard columns <code>import_year</code>, <code>import_month</code> and <code>inport_day</code>.</li>
<li><code>get_latest_partitions_optimized</code> is a quicker version using <code>filter()</code> instead of <code>where()</code></li>
<li><code>get_latest_snapshot_optimized</code> is the same function as above but uses the partition name <code>snapshot_date</code> instead of <code>import_date</code>.</li>
<li><code>get_latest_rows_by_date</code> is the version to use if the partition name is not standard <code>import_date</code> or <code>snapshot_date</code>. This function lets you pass the partition name as a parameter.</li>
</ul>
<ol start="2">
<li>Call the method after having loaded the data into a dataframe. It requires a Spark dataframe, not a Glue Dynamic Frame, so you must convert your dynamic frame if necessary.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Using get_latest_snapshot after loading the data" src="/Data-Platform-Playbook/assets/images/using_get_latest_snapshot_after_loading_data-7d44332b1e50e22c6c7ab1b1d8587200.png" width="1770" height="514" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>We&#x27;ve covered different approaches to make sure the job only processes the data it needs. Many jobs use both filtering before and after loading data into the dataframe. Normally, using a pushdown predicate based on the lasted partition from the Glue catalogue can be used on its own and doesn&#x27;t require further filtering. Also remember that working from the Trusted zone is he best way to only get the latest data, without needing to filter out older partitions!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Data-Platform-Playbook/tags/playbook">playbook</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/playbook/transforming-data/using-aws-glue/optimizing-glue-jobs.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-sagemaker"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Prototyping glue jobs in a notebook</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/practical-examples/scheduling-liberator-glue-jobs"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Scheduling Liberator Glue Jobs</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#filtering-data-before-creating-the-dataframe" class="table-of-contents__link toc-highlight">Filtering data before creating the dataframe</a></li><li><a href="#job-bookmarks" class="table-of-contents__link toc-highlight">Job bookmarks</a><ul><li><a href="#how-it-works" class="table-of-contents__link toc-highlight">How it works</a></li><li><a href="#pros" class="table-of-contents__link toc-highlight">Pros</a></li><li><a href="#cons" class="table-of-contents__link toc-highlight">Cons</a></li><li><a href="#scenarios-when-not-to-use-it" class="table-of-contents__link toc-highlight">Scenarios when not to use it</a></li><li><a href="#how-to-use-it-in-a-job" class="table-of-contents__link toc-highlight">How to use it in a job</a></li><li><a href="#external-doc-about-job-bookmarks" class="table-of-contents__link toc-highlight">External doc about job bookmarks</a></li></ul></li><li><a href="#pushdown-predicates" class="table-of-contents__link toc-highlight">Pushdown predicates</a><ul><li><a href="#pushdown-predicate-based-on-the-current-date--a-few-days-buffer" class="table-of-contents__link toc-highlight">Pushdown predicate based on the current date + a few days buffer</a></li><li><a href="#pushdown-predicate-based-on-the-max-value-of-date-partition-registered-in-the-glue-catalogue" class="table-of-contents__link toc-highlight">Pushdown predicate based on the max value of date partition registered in the Glue catalogue</a></li><li><a href="#pushdown-predicate-based-on-the-latest-written-partition-registered-in-the-glue-catalogue" class="table-of-contents__link toc-highlight">Pushdown predicate based on the latest written partition registered in the Glue catalogue</a></li><li><a href="#external-documentation-about-pushdown-predicates" class="table-of-contents__link toc-highlight">External documentation about pushdown predicates</a></li></ul></li><li><a href="#filtering-data-after-creating-the-dataframe" class="table-of-contents__link toc-highlight">Filtering data after creating the dataframe</a><ul><li><a href="#pros-4" class="table-of-contents__link toc-highlight">Pros</a></li><li><a href="#cons-4" class="table-of-contents__link toc-highlight">Cons</a></li><li><a href="#how-to-use-it-in-a-job-4" class="table-of-contents__link toc-highlight">How to use it in a job</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Made by Hackney's Data Analytics Platform Team.</div></div></div></footer></div>
</body>
</html>