<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="search" type="application/opensearchdescription+xml" title="Hackney Data Platform Playbook" href="/Data-Platform-Playbook/opensearch.xml"><title data-react-helmet="true">Ingesting data from databases into the Data Platform | Hackney Data Platform Playbook</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://playbook.hackney.gov.uk//Data-Platform-Playbook/playbook/ingesting-data/database-ingestion"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Ingesting data from databases into the Data Platform | Hackney Data Platform Playbook"><meta data-react-helmet="true" name="description" content="Ingesting database tables into the Data Platform using a JDBC Connection"><meta data-react-helmet="true" property="og:description" content="Ingesting database tables into the Data Platform using a JDBC Connection"><link data-react-helmet="true" rel="shortcut icon" href="/Data-Platform-Playbook/img/favicon.png"><link data-react-helmet="true" rel="canonical" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/playbook/ingesting-data/database-ingestion"><link data-react-helmet="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/playbook/ingesting-data/database-ingestion" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/playbook/ingesting-data/database-ingestion" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/Data-Platform-Playbook/assets/css/styles.1180568a.css">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/runtime~main.e4e8c851.js" as="script">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/main.2126082f.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Data-Platform-Playbook/"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">Data Platform Playbook</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/LBHackney-IT/data-platform-playbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">About</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Playbook</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Training Modules</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Getting set up on the platform</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Finding data on the platform</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Getting access to data</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#" tabindex="0">Ingesting data</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/google-sheets-import">Ingesting data from Google Sheets</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/manual-ingest-of-csv-files">Ingest manually uploaded csv files</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/ingest-xlsx-files-from-g-drive">Ingest XLXS files from G Drive</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone">Ingesting RDS snapshot into the Data Platform Landing Zone</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/database-ingestion">Ingesting data from databases into the Data Platform</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/playbook/ingesting-data/ingesting-dynamo-db-tables">Ingesting Dynamo DB tables into the Landing Zone</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Transforming data</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Querying and analysing data</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Technical Documentation</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Architecture Decision</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Spikes</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/glossary">Glossary</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/roles">Roles</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Ingesting data from databases into the Data Platform</h1></header><p>This guide explains the process of ingesting data/tables from databases into the Data Platform using AWS Glue JDBC Connection.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="prerequisites"></a>Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">#</a></h2><ul><li>Check that your database type is supported by AWS Glue JDBC Connection (see <a href="https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html" target="_blank" rel="noopener noreferrer">AWS Glue JDBC Connection Properties</a> section) </li><li>Ensure that your database allows user login/authentication, and you have a database user with login credentials<ul><li>If you would like to restrict access to only a selection of tables in your database, then ensure the database&#x27;s user permissions are updated to reflect this</li><li>In addition to the database name and user login credentials, you will also need:<ul><li>the type of database you want to connect to e.g. <code>mssql</code></li><li>the database host name/ endpoint</li><li>the database port number</li></ul></li><li>These will be used to construct the <a href="#construct-the-jdbc-url">JDBC URL</a> in a later section</li></ul></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="overview"></a>Overview<a class="hash-link" href="#overview" title="Direct link to heading">#</a></h2><p>In the following sections you will set up a connection from the Data Platform to your source database to ingest its data, which will involve:</p><ul><li>Authenticating access to the source database from the Data Platform by adding the database credentials to AWS Secrets Manager</li><li>Establishing a connection to the respective database by creating a Glue connection using a JDBC URL which uses the source database&#x27;s credentials stored in Secrets Manager</li><li>Populating a Glue Catalog database with the source database&#x27;s table schemas and metadata by creating a Crawler and crawling the source database</li><li>Pulling in the data from the source database and writing to the Data Platform S3 storage by creating a Glue job which uses the Glue connection as well as the table schemas and metadata from the Glue Catalog database   </li><li>Making the data available for querying in Athena and other Glue jobs by creating a Crawler to crawl the tables in S3 which will then populate a predetermined Glue Catalog database</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="add-the-database-credentials-to-the-data-platform-project"></a>Add the database credentials to the Data Platform project<a class="hash-link" href="#add-the-database-credentials-to-the-data-platform-project" title="Direct link to heading">#</a></h3><p>The database credentials are retrieved from AWS Secrets Manager.
The credentials are used to allow the Data Platform to authenticate against the source database.</p><ul><li><p>Contact a member of the Data Platform team to add the database credentials to Secrets Manager.</p><ul><li><p>You will need to request that a <strong>secret</strong> (with an appropriate description) is created following the naming convention below: </p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">database-credentials/DATABASE_NAME-DATASET_NAME</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>e.g. <code>database-credentials/geolive-permits</code></p></li><li><p>Request that the following key-value pairs be added to this secret:</p><ul><li><code>database_name</code> = <code>&quot;Name of your database&quot;</code></li><li><code>username</code> = <code>&quot;Your database user username&quot;</code></li><li><code>password</code> = <code>&quot;Your database user password&quot;</code></li></ul></li></ul></li></ul><ul><li>Once the credentials have been added, you will be given a secret name which will be used to reference your stored credentials.
Make a note of this as it will be needed in the <a href="#set-up-the-glue-jdbc-connection">Set up the Glue JDBC Connection section</a> below.
</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="construct-the-jdbc-url"></a>Construct the JDBC URL<a class="hash-link" href="#construct-the-jdbc-url" title="Direct link to heading">#</a></h3><p>In this section, you will create the JDBC URL which will be used in the section below.</p><p>Generally JDBC URLs for different types of databases are quite similar.
However, some differ slightly. You will be using the following to construct the JDBC URL:</p><ul><li>Database type</li><li>Database name</li><li>Database host/ endpoint e.g. <code>127.0.0.1</code></li><li>Database port number e.g. <code>1433</code></li></ul><p>Refer to <a href="https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html" target="_blank" rel="noopener noreferrer">AWS Glue JDBC Connection Properties</a> for examples and guidance on how to construct your JDBC URL.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="set-up-the-glue-jdbc-connection"></a>Set up the Glue JDBC Connection<a class="hash-link" href="#set-up-the-glue-jdbc-connection" title="Direct link to heading">#</a></h3><p>Here you will configure a module which will set up the connection to the source database, as well as a Crawler to crawl the source database which will retrieve the
metadata and schemas of the database tables to populate in a Glue Catalog database.
The module will also create a Glue Workflow which the Crawler will be added to.
You can then use this workflow to link your ingestion Glue job (and Crawler) which you will be creating in the following section.
This will help facilitate the automation of the entire database ingestion process.</p><div class="admonition admonition-important alert alert--info"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>important</h5></div><div class="admonition-content"><p>The Crawler will run automatically every weekday at 6am, however, in order to ingest your data on the same day of deployment, you will need to run it manually in the AWS Console.
It will have the same name as the value you set for the <strong>name</strong> input variable in this section. </p></div></div><p><em>For more technical details on the overall process, see: <a href="/Data-Platform-Playbook/spikes/mssql-ingestion">Database Ingestion documentation</a></em></p><ol><li>Open the <a href="https://github.com/LBHackney-IT/Data-Platform/tree/main/terraform" target="_blank" rel="noopener noreferrer">terraform directory</a> in the Data Platform Project in GitHub.<ul><li>If you don&#x27;t have the correct permissions, you&#x27;ll get a &#x27;404&#x27; error (see <a href="/Data-Platform-Playbook/playbook/getting-set-up/index">Getting Set Up on the Platform</a>).</li></ul></li></ol><p><strong>Note: If the data you&#x27;re ingesting is for a specific department then it should be ingested into that department&#x27;s <code>raw zone</code> S3 bucket, otherwise it should go into the <code>landing zone</code></strong> S3 bucket.</p><ol><li><p>Create a new file <code>29-&lt;YOUR-DEPARTMENT-NAME&gt;-&lt;DATABASE-NAME&gt;-database-ingestion.tf</code> if department specific, otherwise <code>29-&lt;DATABASE-NAME&gt;-database-ingestion.tf</code> </p><p>For example, for Academy (database), which is not department specific, the file name will be:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">29-academy-database-ingestion.tf</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><ul><li><em>Refer to this <a href="#example-module-block">example</a> to get started.</em></li></ul></li><li><p>Copy the <a href="#example-module-block">example module block</a> paste it in your file.</p></li><li><p>Update the <code>module</code> name using the following name convention: </p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&lt;department_name&gt;_&lt;database_name&gt;_database_ingestion</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p><em>Note: the department name must be all lowercase and separated by underscores</em></p><p> For example: </p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;academy_lbhatestrbviews_database_ingestion&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li><li><p>Update or add your input variables.</p></li></ol><ul><li><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="the-following-input-variables-are-required"></a>The following input variables are required:<a class="hash-link" href="#the-following-input-variables-are-required" title="Direct link to heading">#</a></h4><ul><li><p><strong>source</strong> (required): This will be <code>&quot;../modules/database-ingestion-via-jdbc-connection&quot;</code>. It is the path to where the database ingestion module is saved within the repository</p><ul><li><em><strong>Note</strong>: If you&#x27;ve copied the example module block then you wonâ€™t need to change the <strong>source</strong> variable</em></li></ul></li><li><p><strong>name</strong> (required): Name of the dataset that will be ingested in all <strong>lowercase letters</strong> with <strong>words separated by hyphens</strong>. e.g. <code>&quot;revenue-benefits-and-council-tax&quot;</code></p><ul><li>This will be the name of all your resources created as part of this step and will be needed to identify your resources in the AWS Console when populating the Glue job parameters to prototype your Glue job.</li></ul></li><li><p><strong>jdbc_connection_url</strong> (required): This will be in the format: <code>jdbc:protocol://host:port/db_name</code></p><ul><li><p>Set this to the JDBC URL you constructed in the previous section.
You can refer to <a href="https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html" target="_blank" rel="noopener noreferrer">AWS Glue JDBC Connection Properties</a> for more guidance on how to construct your JDBC URL. </p><p>For example, a SQL Server database&#x27;s JDBC URL will look like this: </p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">jdbc_connection_url = &quot;jdbc:sqlserver://10.120.23.22:1433;databaseName=LBHATestRBViews&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li></ul></li><li><p><strong>jdbc_connection_description</strong> (required): A description of the connection i.e. The type of connection, database and dataset that will be ingested
For example:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;JDBC connection to Academy Production Insights LBHATestRBViews database to ingest Council Tax data&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li><li><p><strong>jdbc_connection_subnet_id</strong> (required): The subnet to deploy the connection to.
Set this to <code>local.subnet_ids_list[local.subnet_ids_random_index]</code></p></li><li><p><strong>database_availability_zone</strong> (required): The availability zone to deploy the connection to.
Set this to <code>&quot;eu-west-2a&quot;</code></p></li><li><p><strong>vpc_id</strong> (required): Set this to <code>data.aws_vpc.network.id</code></p></li><li><p><strong>identifier_prefix</strong> (required): Set this to <code>local.short_identifier_prefix</code></p></li><li><p><strong>database_secret_name</strong> (required): Name of the secret in AWS Secrets Manager where your database credentials are being stored.
This would have been shared with you by a member of the Data Platform team.
For example:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">database_secret_name = &quot;database-credentials/lbhatestrbviews-council-tax&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li><li><p><strong>schema_name</strong> (optional): Name of schema in the database containing tables to be ingested. e.g. <code>&quot;parking&quot;</code>.</p><p>For databases that support schemas, you can provide a schema name here to ingest all tables in the schema within the specified database.
Oracle Database and MySQL donâ€™t support this; therefore <strong>DO NOT</strong> enter a value here.</p></li></ul></li></ul><ol start="6"><li><p>Commit your changes and create a Pull Request for review by the Data Platform team.
You should wait for it to be approved and deployed before moving onto the next step.</p><ul><li>See <a href="/Data-Platform-Playbook/playbook/getting-set-up/using-github#committing-your-changes-to-the-data-platform-project">Committing changes</a> section of the <strong>Using Github</strong> guide.
The Data Platform team needs to approve any changes to the code that you make, so your change won&#x27;t happen automatically.</li></ul></li><li><p>Once you get confirmation that the code has been successfully deployed,
you will need to do the following before moving on to the next section:</p><ul><li>Request that the ID of the security group of the Glue JDBC Connection (created in this module) is added to the source database&#x27;s inbound security group rules by an appropriate engineer of the respective AWS account.<ul><li>You can find the security group ID of your connection by navigating to <code>AWS Glue</code> in the AWS Console,
then clicking <code>Connections</code> in the left-hand navigation bar and then searching for your connection.
It will have the same name that you set in the <strong>name</strong> input variable above.</li><li>Click on your connection and copy the ID next to <code>Security groups</code> e.g. <code>sg-05a4fc711d3e12345</code>.
This is the security group ID you need to provide to the engineer.
</li></ul></li><li>Test your connection and ensure it works:<ul><li>Select your connection and click <code>Test Connection</code>.</li><li>Assign the relevant department IAM role.<ul><li><strong>Note: If the data you are ingesting is not department specific, you should use the IAM role: <code>dataplatform-stg-glue-role</code>.</strong></li></ul></li><li>Lastly, click <code>Test Connection</code> (this can take up to a minute to complete).</li></ul></li></ul></li></ol><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="create-a-glue-job-and-crawler-to-ingest-all-database-tables"></a>Create a Glue job and Crawler to ingest all database tables<a class="hash-link" href="#create-a-glue-job-and-crawler-to-ingest-all-database-tables" title="Direct link to heading">#</a></h3><p>Once your Pull Request for setting up the JDBC Connection has been approved and deployed, you can continue with this section.</p><p>Here you will create a Glue job which will use the JDBC connection you&#x27;ve just created to pull the database tables into S3.
You will also create a Crawler to read all the ingested tables from S3 and populate a Glue Catalog Database so that the
data can be queried in Athena or consumed by other Glue jobs for further processing.</p><div class="admonition admonition-important alert alert--info"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>important</h5></div><div class="admonition-content"><p>If your data is <strong>NOT</strong> department specific, you will not be able to crawl the S3 output location to populate a Glue Catalog database and therefore you should <strong>NOT</strong> set any configurations in the <code>crawler_details</code> input variable (delete this input variable if necessary).  </p></div></div><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="prototyping-your-glue-job"></a>Prototyping your Glue job<a class="hash-link" href="#prototyping-your-glue-job" title="Direct link to heading">#</a></h4><p>You can prototype your Glue job and test ingesting a few tables by referring to and cloning an existing Glue job.
You can search for the <code>&quot;stg Revenue &amp; Benefits and Council Tax Database Ingestion&quot;</code> Glue job in the list of jobs in the <a href="https://eu-west-2.console.aws.amazon.com/gluestudio/home?region=eu-west-2#/jobs" target="_blank" rel="noopener noreferrer">AWS Console</a>
to use as an example. You can also refer to the <a href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio">Using Glue Studio</a> guide for guidance on prototyping your Glue job.</p><p>To prototype your script you will need to manually set/ update all the Glue Job parameters and Connections in the <code>Job Details</code> tab:</p><ul><li>The <code>source_catalog_database</code> Glue Job parameter and the <code>Connections</code> input variable should be the same as what you set for the <strong>name</strong> input variable in the previous section.</li></ul><p>The example Glue job linked above will read all the tables and output them to a specified S3 location.</p><ul><li>It uses two helper functions which are imported from <code>helpers.py</code>, these are: <ul><li><code>get_all_database_tables</code>: used to retrieve all the table names from the specified Glue Catalog Database</li><li><code>update_table_ingestion_details</code>: used to create a dataframe containing stats, including errors, on the ingestion process for each table</li></ul></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="deploying-your-glue-job"></a>Deploying your Glue job<a class="hash-link" href="#deploying-your-glue-job" title="Direct link to heading">#</a></h4><div class="admonition admonition-important alert alert--info"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>important</h5></div><div class="admonition-content"><p>Before continuing with this section, ensure that you have deleted any data that was copied to S3 whilst prototyping your Glue job.</p></div></div><p>When you are ready to deploy your Glue job (and Crawler) to the Data Platform project, you can continue with the below steps.
Your Glue job will copy all the tables from your source database to S3 which will then be crawled and populated in a Glue Catalog Database where the tables can be queried.
Spark Web UI is used to monitior and debug the glue jobs. Every 30 seconds, AWS Glue flushes the Spark event logs to an S3 bucket titled Spark UI Bucket.</p><p>You will be using the existing <a href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs">Glue job module</a> to deploy your ingestion Glue job and Crawler.</p><ul><li><strong>The steps below only serve as complementary guidance and should be followed along with the official documentation for the Glue job module linked above.</strong></li></ul><p>You can add the Glue job module Terraform code to the same file you created/ updated in the previous section when setting up the Glue JDBC Connection.</p><p><strong>Set the input variables for the Glue job and Crawler</strong> </p><p>The following <strong>input variables</strong> and <strong>job parameters</strong> need to be set:</p><ul><li><p><strong>Input variables</strong> (required):</p><ul><li><p><strong>script_s3_object_key</strong> (required): S3 object key of the script which will be used to ingest the database tables.
Set this to: <code>aws_s3_bucket_object.ingest_database_tables_via_jdbc_connection.key</code></p></li><li><p><strong>jdbc_connections</strong> (required): The list of connections used for this job, i.e. JDBC connection.
This will be <code>[module.&lt;NAME_OF_CONNECTION_MODULE&gt;[0].jdbc_connection_name]</code>.
See step 4 in the section: <a href="#set-up-the-glue-jdbc-connection">set up the glue JDBC connection</a> above for a reminder of the module name.</p><p>For example: </p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">[module.academy_lbhatestrbviews_database_ingestion[0].jdbc_connection_name]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p><em>Note: ensure there are surrounding square brackets (<code>[]</code>) around the value provided here</em></p></li><li><p><strong>triggered_by_crawler</strong> (optional): You can configure your job to run automatically once the Crawler created in the previous section has run successfully.</p><ul><li>To add this trigger, set this input variable to: <div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">module.&lt;NAME_OF_CONNECTION_MODULE&gt;[0].crawler_name</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li></ul><p>If you don&#x27;t populate this variable then the Glue job and Crawler will need to be run manually in the AWS Console.</p><p>If you want it to run on a schedule then please refer to the <strong>&quot;Variables used for scheduling a Glue job&quot;</strong> section of <a href="/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs#variables-used-for-scheduling-a-glue-job">this article</a> for an explanation on how to set the variables to do so.
</p></li><li><p><strong>workflow_name</strong> (optional): Workflow to add your Glue job (and Crawler to).
This is required if you set a <strong>schedule</strong> or set the input variable <strong>triggered_by_crawler</strong> above.</p><ul><li>To add your Glue job (and Crawler) to a workflow, set this input variable to:<div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">module.&lt;NAME_OF_CONNECTION_MODULE&gt;[0].workflow_name</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li></ul></li></ul></li><li><p><strong>Job parameters</strong>:</p><ul><li><p>Note: For the following optional <strong>job parameters</strong>; <em>&quot;--s3_ingestion_bucket_target&quot;</em> and <em>&quot;--s3_ingestion_details_target&quot;</em>:</p><ul><li><code>&lt;ZONE&gt;</code> refers to either: <code>raw</code> or <code>landing</code> S3 zones</li><li><strong>If the data you&#x27;re ingesting is for a specific department then it should be ingested into that department&#x27;s <code>raw</code> zone, otherwise it should go into the <code>landing</code> zone</strong></li></ul></li><li><p><em>&quot;--source_catalog_database&quot;</em> (required): The Glue Catalog Database where your databases&#x27; table schemas are stored</p><ul><li><p>This will be <code>module.&lt;NAME_OF_CONNECTION_MODULE&gt;[0].ingestion_database_name</code>.</p><p>For example:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">module.academy_lbhatestrbviews_database_ingestion[0].ingestion_database_name</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li></ul></li><li><p><em>&quot;--s3_ingestion_bucket_target&quot;</em> (required): The S3 location where the ingested tables should be stored</p><p>For example:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;--s3_ingestion_bucket_target&quot; = &quot;s3://${module.&lt;ZONE&gt;_zone.bucket_id}/&lt;YOUR-DEPARTMENT-NAME&gt;/&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><ul><li><em>Note: ensure that your department name and folder name is all <strong>lowercase</strong> with <strong>words separated by hyphens</strong>
e.g. <code>housing-repairs</code>.</em></li></ul></li><li><p><em>&quot;--s3_ingestion_details_target&quot;</em> (required): The S3 location where the ingestion details should be stored </p><p>  <em>Note: in order for the Crawler to add your ingestion details to the Glue Catalog Database so that they can be analysed in Athena later,
you should set this parameter to have one additional folder level (e.g.<code>ingestion-details</code>) to what was set in <strong><code>s3_ingestion_bucket_target</code></strong></em>.</p><p>  For example:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;--s3_ingestion_details_target&quot; = &quot;s3://${module.&lt;ZONE&gt;_zone.bucket_id}/&lt;YOUR-DEPARTMENT-NAME&gt;/ingestion-details/&quot;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><ul><li><em>Note: ensure that your department name is all <strong>lowercase</strong> with <strong>words separated by underscores</strong>
e.g. <code>housing_repairs</code>.</em></li></ul></li><li><p><strong>crawler_details</strong>:</p><div class="admonition admonition-caution alert alert--warning"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></div><div class="admonition-content"><p><strong>If your data is department specific, you should set the following parameters.</strong>
Otherwise, if your data is <strong>NOT</strong> department specific, or <strong>NOT</strong> &quot;unrestricted&quot; data, and is being written to the <strong>landing</strong> zone, you should <strong>NOT</strong> set any of the below parameters (deleting the entire <code>crawler_details</code> configuration if present or working with a duplicated module block).
In that case, the data will need to be moved to <strong>raw</strong> zone, and a specific <strong>department</strong> before it can be crawled and queried in Athena.</p></div></div><ul><li><p><em>database_name</em> (required): Glue database where results are written after being crawled</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">module.department_&lt;YOUR_DEPARTMENT_NAME&gt;.&lt;S3_BUCKET_ZONE&gt;_zone_catalog_database_name</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><ul><li>Where <code>&lt;S3_BUCKET_ZONE&gt;</code> will be: <code>raw</code>. The same zone you wrote the data to in S3.</li></ul></li><li><p><em>s3_target_location</em> (required): This should be the same as <strong><code>&quot;--s3_ingestion_bucket_target&quot;</code></strong> set above</p></li><li><p><em>configuration</em> (required): Set the <code>TableLevelConfiguration</code> to 1 plus the number of directory levels in <strong><code>&quot;--s3_ingestion_bucket_target&quot;</code></strong></p><p>For example: The value for <code>TableLevelConfiguration</code> with an <strong>s3_ingestion_bucket_target</strong> of <code>&quot;s3://${module.raw_zone.bucket_id}/academy/&quot;</code> will be <code>3</code> </p><p>A complete example of <strong>crawler_details</strong> can be seen below:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">crawler_details = {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    database_name      = module.department_academy.raw_zone_catalog_database_name </span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    s3_target_location = &quot;s3://${module.raw_zone.bucket_id}/academy/&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    configuration = jsonencode({</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Version = 1.0</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Grouping = {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            TableLevelConfiguration = 3</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    })</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></li></ul></li></ul></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="commit-your-changes-and-create-a-pull-request-for-review-by-the-data-platform-team"></a>Commit your changes and create a Pull Request for review by the Data Platform team<a class="hash-link" href="#commit-your-changes-and-create-a-pull-request-for-review-by-the-data-platform-team" title="Direct link to heading">#</a></h3><p>You can now submit your changes for review by the Data Platform team.</p><ul><li>See <a href="/Data-Platform-Playbook/playbook/getting-set-up/using-github#committing-your-changes-to-the-data-platform-project">Committing changes</a> section of the <strong>Using Github</strong> guide.
The Data Platform team needs to approve any changes to the code that you make, so your change won&#x27;t happen automatically.
Once your changes have been approved and deployed, the job will run at the next scheduled time (if scheduled).</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="running-the-ingestion-manually"></a>Running the ingestion manually<a class="hash-link" href="#running-the-ingestion-manually" title="Direct link to heading">#</a></h3><p>Once you have been notified that your Pull Request has been merged, you can run the ingestion manually from the AWS Console or wait until the scheduled time (if you&#x27;ve set one).</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="complete-example-with-both-glue-jdbc-connection-and-glue-job-modules"></a>Complete example with both Glue JDBC Connection and Glue job modules<a class="hash-link" href="#complete-example-with-both-glue-jdbc-connection-and-glue-job-modules" title="Direct link to heading">#</a></h3><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">module &quot;academy_mssql_database_ingestion&quot; {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    count = local.is_live_environment ? 1 : 0</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tags  = module.tags.values</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    source = &quot;../modules/database-ingestion-via-jdbc-connection&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name                        = &quot;revenue-benefits-and-council-tax&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    jdbc_connection_url         = &quot;jdbc:sqlserver://10.120.23.22:1433;databaseName=LBHATestRBViews&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    jdbc_connection_description = &quot;JDBC connection to Academy Production Insights LBHATestRBViews database&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    jdbc_connection_subnet_id   = local.subnet_ids_list[local.subnet_ids_random_index]</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    database_availability_zone  = &quot;eu-west-2a&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    database_secret_name        = &quot;database-credentials/lbhatestrbviews-council-tax&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    identifier_prefix           = local.short_identifier_prefix</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    vpc_id                      = data.aws_vpc.network.id</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">module &quot;ingest_rev_bev_council_tax&quot; {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  count = local.is_live_environment ? 1 : 0</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  tags  = module.tags.values</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  source = &quot;../modules/aws-glue-job&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  job_name               = &quot;${local.short_identifier_prefix}Revenue &amp; Benefits and Council Tax Database Ingestion&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  script_s3_object_key   = aws_s3_bucket_object.ingest_database_tables_via_jdbc_connection.key</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  environment            = var.environment</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  pydeequ_zip_key        = aws_s3_bucket_object.pydeequ.key</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  helper_module_key      = aws_s3_bucket_object.helpers.key</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  jdbc_connections       = [module.academy_mssql_database_ingestion[0].jdbc_connection_name]</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  glue_role_arn          = aws_iam_role.glue_role.arn</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  glue_temp_bucket_id    = module.glue_temp_storage.bucket_id</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  glue_scripts_bucket_id = module.glue_scripts.bucket_id</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  workflow_name          = module.academy_mssql_database_ingestion[0].workflow_name</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  triggered_by_crawler   = module.academy_mssql_database_ingestion[0].crawler_name</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  job_parameters = {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--source_data_database&quot;             = module.academy_mssql_database_ingestion[0].ingestion_database_name</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--s3_ingestion_bucket_target&quot;       = &quot;s3://${module.raw_zone.bucket_id}/academy/&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--s3_ingestion_details_target&quot;      = &quot;s3://${module.raw_zone.bucket_id}/academy/ingestion-details/&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--TempDir&quot;                          = &quot;s3://${module.glue_temp_storage.bucket_id}/&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--extra-py-files&quot;                   = &quot;s3://${module.glue_scripts.bucket_id}/${aws_s3_bucket_object.helpers.key}&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--extra-jars&quot;                       = &quot;s3://${module.glue_scripts.bucket_id}/jars/deequ-1.0.3.jar&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;--enable-continuous-cloudwatch-log&quot; = &quot;true&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  }</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  crawler_details = {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    database_name      = module.department_academy.raw_zone_catalog_database_name </span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    s3_target_location = &quot;s3://${module.raw_zone.bucket_id}/academy/&quot;</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    configuration = jsonencode({</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      Version = 1.0</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      Grouping = {</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        TableLevelConfiguration = 3</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      }</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    })</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  }</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/Data-Platform-Playbook/tags/playbook">playbook</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/playbook/ingesting-data/005-database-ingestion.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_13-_"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/Data-Platform-Playbook/playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Ingesting RDS snapshot into the Data Platform Landing Zone</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/Data-Platform-Playbook/playbook/ingesting-data/ingesting-dynamo-db-tables"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Ingesting Dynamo DB tables into the Landing Zone Â»</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prerequisites" class="table-of-contents__link">Prerequisites</a></li><li><a href="#overview" class="table-of-contents__link">Overview</a><ul><li><a href="#add-the-database-credentials-to-the-data-platform-project" class="table-of-contents__link">Add the database credentials to the Data Platform project</a></li><li><a href="#construct-the-jdbc-url" class="table-of-contents__link">Construct the JDBC URL</a></li><li><a href="#set-up-the-glue-jdbc-connection" class="table-of-contents__link">Set up the Glue JDBC Connection</a></li><li><a href="#create-a-glue-job-and-crawler-to-ingest-all-database-tables" class="table-of-contents__link">Create a Glue job and Crawler to ingest all database tables</a></li><li><a href="#commit-your-changes-and-create-a-pull-request-for-review-by-the-data-platform-team" class="table-of-contents__link">Commit your changes and create a Pull Request for review by the Data Platform team</a></li><li><a href="#running-the-ingestion-manually" class="table-of-contents__link">Running the ingestion manually</a></li><li><a href="#complete-example-with-both-glue-jdbc-connection-and-glue-job-modules" class="table-of-contents__link">Complete example with both Glue JDBC Connection and Glue job modules</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Made by HackIT.</div></div></div></footer></div>
<script src="/Data-Platform-Playbook/assets/js/runtime~main.e4e8c851.js"></script>
<script src="/Data-Platform-Playbook/assets/js/main.2126082f.js"></script>
</body>
</html>