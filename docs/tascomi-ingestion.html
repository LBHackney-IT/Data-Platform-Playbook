<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-docs/tascomi-ingestion">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.20">
<link rel="search" type="application/opensearchdescription+xml" title="Hackney Data Platform Playbook" href="/Data-Platform-Playbook/opensearch.xml"><title data-rh="true">Tascomi data ingestion | Hackney Data Platform Playbook</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tascomi data ingestion | Hackney Data Platform Playbook"><meta data-rh="true" name="description" content="Description of the ingestion and refinement pipeline for Tascomi planning data"><meta data-rh="true" property="og:description" content="Description of the ingestion and refinement pipeline for Tascomi planning data"><link data-rh="true" rel="icon" href="/Data-Platform-Playbook/img/favicon.png"><link data-rh="true" rel="canonical" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion"><link data-rh="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion" hreflang="en"><link data-rh="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://KNMFHOJ4X2-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/Data-Platform-Playbook/assets/css/styles.4438b1b5.css">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/runtime~main.6ed04a66.js" as="script">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/main.aa2b627a.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Data-Platform-Playbook/"><div class="navbar__logo"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title text--truncate">Data Platform Playbook</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/LBHackney-IT/data-platform-playbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_dLyj"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_mKqt"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><div class="docPage_ualW"><aside class="theme-doc-sidebar-container docSidebarContainer_UQUJ"><div class="sidebar_RiAD"><nav class="menu thin-scrollbar menu_izAj"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Data-Platform-Playbook/">About</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Data-Platform-Playbook/playbook/getting-set-up">Playbook</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Data-Platform-Playbook/training-modules/module-0">Training Modules</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/Data-Platform-Playbook/docs/CD-process">Technical Documentation</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/CD-process">CD Process</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/CI-process">CI Process</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/academy-ingestion">Ingesting Academy data onto the Data Platform</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/auto-adjusting-aws-budget">Auto-adjusting AWS Budget Alerts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/backdated-liberator-ingestion">Backdated Liberator data ingestion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/exporting-snapshot-to-landing-zone">Exporting database snapshots to the Data Platform Landing Zone</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/import-external-files-to-landing-zone">Importing external files to the Data Platform Landing Zone</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/import-spreadsheet-from-g-drive">Import spreadsheets from G Drive</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/liberator-ingestion">Liberator data ingestion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/redshift">Redshift - Creating users, databases and exposing data from Glue</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Data-Platform-Playbook/docs/tascomi-ingestion">Tascomi data ingestion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account">VPC Peering Connection between Data Platform and Production APIs AWS accounts</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Data-Platform-Playbook/architecture-decisions">Architecture Decision</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Data-Platform-Playbook/spikes/amundsen-deployment">Spikes</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/glossary">Glossary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/roles">Roles</a></li></ul></nav></div></aside><main class="docMainContainer_uL0j"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Xlws" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Data-Platform-Playbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_kU5B"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Technical Documentation</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Tascomi data ingestion</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_bZGK theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_l22C">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tascomi data ingestion</h1></header><p>This section describes how Tascomi Planning data gets ingested and refined in the data platform. The process relies on <a href="https://hackney-planning.tascomi.com/rest/v1/documentation.html?public_key=dd95bcd473f46a4325a4021d54500c7d#available-resources" target="_blank" rel="noopener noreferrer">Tascomi API</a> and is composed of the following steps:</p><ul><li>An initial full ingestion from Tascomi API (only once, happened in October 2021)</li><li>A daily call to the Tascomi API to get latest updated records (increment)</li><li>Parsing of the json data increment returned by the API</li><li>Refinement of the parsed data to recast all columns to the right data type</li><li>Creation of a full snapshot by applying the daily increment to the previous snapshot</li></ul><p><img loading="lazy" alt="Tascomi data ingestion process" src="/Data-Platform-Playbook/assets/images/tascomi-ingestion-pipeline-e34ac24b998aac993115d0d9822a3ed5.png" width="3470" height="1620" class="img_E7b_"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="details-of-individual-steps">Details of individual steps<a class="hash-link" href="#details-of-individual-steps" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="step-1---ingestion">Step 1 - Ingestion<a class="hash-link" href="#step-1---ingestion" title="Direct link to heading">​</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_api_ingestion.py" target="_blank" rel="noopener noreferrer">process</a> queries one API endpoint (e.g. the applications endpoint) and writes the data into a table of the same name. This process writes into the raw zone bucket, with the &#x27;api_response&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="11---initial-full-ingestion">1.1 - Initial full ingestion<a class="hash-link" href="#11---initial-full-ingestion" title="Direct link to heading">​</a></h4><p>This initial run imported the full Tascomi tables</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="12---daily-ingestion-of-latest-updated-records">1.2 - Daily ingestion of latest updated records<a class="hash-link" href="#12---daily-ingestion-of-latest-updated-records" title="Direct link to heading">​</a></h4><p>The subsequent runs only ingest the records updated since the last import. The process relies on the <code>last_updated</code> column that is present on all Tascomi tables.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="step-2---daily-parsing-of-the-json-increments">Step 2 - Daily parsing of the json increments<a class="hash-link" href="#step-2---daily-parsing-of-the-json-increments" title="Direct link to heading">​</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_parse_tables_increments.py" target="_blank" rel="noopener noreferrer">process</a> uses job bookmarking to only process new increments. It also uses a pushdown predicate to only load the last 5 daily prtitions (it is quicker than loading the full dataset).
It processes all tables in a loop. For each table, the large json blob containing all the fields is exploded into separate textual columns.</p><p>This process writes into the raw zone bucket, with the &#x27;planning/tascomi/parsed&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="step-3---daily-refinement-of-the-parsed-increments">Step 3 - Daily refinement of the parsed increments<a class="hash-link" href="#step-3---daily-refinement-of-the-parsed-increments" title="Direct link to heading">​</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_recast_tables_increments.py" target="_blank" rel="noopener noreferrer">process</a> uses job bookmarking to only process new increments.
It processes all tables in a loop. For each table, the text columns are converted into correct data types (dates, boolean etc.). It uses a <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi-column-type-dictionary.json" target="_blank" rel="noopener noreferrer">column type dictionary</a> saved in S3 in a separate json file. This dictionary was created semi-automatically with FME (an ETL tool used in the Data and Insight team), by converting the list of columns described in the <a href="https://hackney-planning.tascomi.com/rest/v1/documentation.html?public_key=dd95bcd473f46a4325a4021d54500c7d#available-resources" target="_blank" rel="noopener noreferrer">API endpoints documentation</a>.</p><p>This process writes into the refined zone bucket, with the &#x27;planning/tascomi/increment&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="step-4---creation-of-the-daily-snapshot">Step 4 - Creation of the daily snapshot<a class="hash-link" href="#step-4---creation-of-the-daily-snapshot" title="Direct link to heading">​</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_create_daily_snapshot.py" target="_blank" rel="noopener noreferrer">process</a> combines the latest snapshot and all increments created since that day, to create a new snapshot. It uses pushdown predicate and job bookmarking to only process new increments. Like the 2 previous steps, it processes all tables in a loop. If several days increments need to be applied, the process first ensures that no duplicate records are present, by only keeping the latest updated one (for instance, if a planning application has changed status 2 times, it only keeps the record with the latest status). To apply the increments to the previous snapshot, we just replace pre-existing records with the newer version, using the unique id. A new column &#x27;snapshot_date&#x27; is created and set to the current date.</p><p>This process writes into the refined zone bucket, with the &#x27;planning/tascomi/snapshot&#x27; prefix. The data is partitioned by <code>snapshot_date</code>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="step-5---creation-of-latest-tables-in-the-trusted-zone">Step 5 - Creation of latest tables in the Trusted zone<a class="hash-link" href="#step-5---creation-of-latest-tables-in-the-trusted-zone" title="Direct link to heading">​</a></h3><p>This steps takes latest snapshots of a few tables in the refined zone, simplifies them and joins them together to create a few tables in the trusted zone, ready for ingestion in Qlik and for use by Planning analysts. It is composed of 4 jobs: <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_applications_trusted.py" target="_blank" rel="noopener noreferrer">applications to trusted</a>, <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_locations_trusted.py" target="_blank" rel="noopener noreferrer">locations to trusted</a>, <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_subsidiary_tables.py" target="_blank" rel="noopener noreferrer">subsidiary tables to trusted</a>, <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_officers_trusted.py" target="_blank" rel="noopener noreferrer">officers to trusted</a>. These jobs always clear the target folder before writing, so the trusted zone only contains one partition corresponding to the latest date. </p><p>In this zone we use a <!-- -->[csv dataset of bank holidays and Hackney non-working days]<!-- --> (<a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/hackney_bank_holiday.csv" target="_blank" rel="noopener noreferrer">https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/hackney_bank_holiday.csv</a>) to calculate time intervals used for performance reporting (e.g. in how many days an application reached the &#x27;registered&#x27; state). The calculation method is in the helpers.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="full-workflow-and-scheduling">Full workflow and scheduling<a class="hash-link" href="#full-workflow-and-scheduling" title="Direct link to heading">​</a></h2><p>The full workflow is defined in the <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/terraform/etl/24-aws-glue-tascomi-data.tf" target="_blank" rel="noopener noreferrer">glue-tascomi-data terraform script</a>.
It defines a list of tables that needs updating everyday, and a list of static tables that are only updated weekly (these are the static tables like application types). The schedule is as follows:</p><ul><li>2am GMT: as many jobs as tables to update are triggered. Each job queries one API endpoint for latest updated records. That&#x27;s 25 jobs on Sundays (including static tables), about half of that on other days.</li><li>4am GMT: a crawler crawls the API responses bucket<ul><li>the previous crawler triggers the <strong>parsing</strong> job and the crawling of its results</li><li>the crawler of the parsing job triggers the <strong>recasting</strong> job and the crawling of its results</li><li>the crawler of the recasting job triggers the <strong>daily snapshot creation</strong> job and the crawling of its results</li><li>the crawler of the snapshot creation job triggers the <strong>applications to trusted</strong> job which in turn triggers the other jobs of the trusted zone.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="structure-of-the-s3-buckets-and-glue-tables">Structure of the S3 buckets and Glue tables<a class="hash-link" href="#structure-of-the-s3-buckets-and-glue-tables" title="Direct link to heading">​</a></h2><p>The data created along the process (initial full load, increments and snapshots) is stored in S3 in the raw and refined zones, with one folder per table.</p><p>The ready-for-use data is in the refined zone bucket with the prefix /planning/tascomi/snapshot. The corresponding tables in the Glue catalog are simply called applications, appeals, etc. To get the latest data, the query must refer to the snapshot_date latest partition, for example</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select * from &quot;dataplatform-prod-tascomi-refined-zone&quot;.&quot;applications&quot; where snapshot_date = (select max(snapshot_date) from &quot;dataplatform-prod-tascomi-refined-zone&quot;.&quot;applications&quot;)</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The refined increments are in the Refined zone Planning bucket, in the <code>increments</code> area. The tables are prefixed with <code>increment_</code>. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-prod-tascomi-refined-zone&quot;.&quot;increment_applications&quot; where import_date = &#x27;20211208&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The parsed increments are in the Raw zone Planning bucket, in the <code>parsed</code> area. The tables are not prefixed, and partitioned by <code>import_date</code> with. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-prod-tascomi-raw-zone&quot;.&quot;applications&quot; where import_date = &#x27;20211208&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The raw data returned by the API is in the Raw zone Planning bucket, in the <code>api_response</code> area. The tables are prefixed with <code>api_response_</code>, and partitioned by <code>import_date</code> with. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-prod-tascomi-raw-zone&quot;.&quot;api_response_applications&quot; where import_date = &#x27;20211208&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-to-add-a-table-to-the-pipeline">How to add a table to the pipeline<a class="hash-link" href="#how-to-add-a-table-to-the-pipeline" title="Direct link to heading">​</a></h2><p>Follow these steps to start ingesting data from a new endpoint available from the API. </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="test-the-endpoint">Test the endpoint<a class="hash-link" href="#test-the-endpoint" title="Direct link to heading">​</a></h3><p>You can use a Jupyter notebook on your local install to check that the endpoint is returning what you expect. It is hard to test with Postman because of the time-dependent token that the Tascomi API is using for authentication.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="create-and-check-out-a-new-branch-in-the-repository">Create and check out a new branch in the repository<a class="hash-link" href="#create-and-check-out-a-new-branch-in-the-repository" title="Direct link to heading">​</a></h3><p>All the changes below should be commited to this branch first.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="add-the-table-to-the-column-type-dictionary">Add the table to the <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi-column-type-dictionary.json" target="_blank" rel="noopener noreferrer">column type dictionary</a><a class="hash-link" href="#add-the-table-to-the-column-type-dictionary" title="Direct link to heading">​</a></h3><p>This json dictionary supports the &#x27;recast increment&#x27; step that converts string columns into their cortect data types. It looks like this:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;long&quot;: {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;applications&quot;: [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;site_address_x&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;site_address_y&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;tree_location_x&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;tree_location_y&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;emails&quot;: [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;last_updated&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;submit_date&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;ceased_date&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;enforcements&quot;: [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;complaint_location_x&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;complaint_location_y&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;dtf_locations&quot;: [&quot;parent_uprn&quot;,&quot;uprn&quot;,&quot;usrn&quot;],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;users&quot;: [&quot;mileage_rate&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;double&quot;: {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;applications&quot;: [</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;affordable_housing_balancing_sum&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;height_of_proposed_development&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_dimensions_breadth&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_dimensions_eaves&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_dimensions_length&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_dimensions_ridge&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_distance_from_proposal&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_building_overall_ground_area&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_fish_tank_cage_depth&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_fish_tank_cage_height&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_fish_tank_cage_length&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                &quot;proposed_fish_tank_cage_width&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            &quot;appeals&quot;: [&quot;appeal_location_x&quot;,&quot;appeal_location_y&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>To amend the catalogue semi-automatically you need to do the following (TODO: create a Python script to replace the FME process)</p><ul><li>Open the <a href="https://hackney-planning.tascomi.com/rest/v1/documentation.html?public_key=dd95bcd473f46a4325a4021d54500c7d#available-resources" target="_blank" rel="noopener noreferrer">Tascomi API resources page</a>. Navigate to the table you&#x27;re adding, select and copy its content.</li><li>Open the <a href="https://docs.google.com/spreadsheets/d/1ZZwWHSoudBgN9j0jV6ZrNZKgXYMOm7ObWTWLT3Xg8Rw/edit?usp=sharing" target="_blank" rel="noopener noreferrer">Tascomi column dictionary Google Sheet</a>, create a new tab for the new table and paste the content you copied in the previous step. Only keep 2 columns: field and type.</li><li>Launch FME desktop, open the Tascomi Dictionary workspace, refresh the feature types in the reader to see the new tab of the Google Sheet. Run the workspace for the new tab. You&#x27;ll get fragments of json that you can copy and paste into the proper dictionary.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="add-the-table-to-the-terraform-script">Add the table to the <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/terraform/etl/24-aws-glue-tascomi-data.tf" target="_blank" rel="noopener noreferrer">Terraform script</a>.<a class="hash-link" href="#add-the-table-to-the-terraform-script" title="Direct link to heading">​</a></h3><p>Decide wether the new table should be ingested daily (in this case append it to the <code>tascomi_table_names</code> list) or weekly (in this case appen it to the <code>tascomi_static_tables</code> list).</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="add-data-quality-tests-in-the-relevant-scripts">Add data quality tests in the relevant scripts<a class="hash-link" href="#add-data-quality-tests-in-the-relevant-scripts" title="Direct link to heading">​</a></h3><p><a href="https://playbook.hackney.gov.uk/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide" target="_blank" rel="noopener noreferrer">Quality testing with PyDeequ</a> is parameterised inside each relevant script. At the moment, only the <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_parse_tables_increments.py" target="_blank" rel="noopener noreferrer">parse table increment script</a> has tests implemented. For your new table to be quality-checked each day, you need to open this script and append a line in this section near the top: </p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">dq_params = {&#x27;appeals&#x27;: {&#x27;unique&#x27;: [&#x27;id&#x27;, &#x27;import_date&#x27;], &#x27;complete&#x27;: &#x27;id&#x27;},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">             &#x27;applications&#x27;: {&#x27;unique&#x27;: [&#x27;id&#x27;, &#x27;import_date&#x27;], &#x27;complete&#x27;: &#x27;application_reference_number&#x27;},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">             &#x27;appeal_decision&#x27;: {&#x27;unique&#x27;: [&#x27;id&#x27;, &#x27;import_date&#x27;], &#x27;complete&#x27;: &#x27;id&#x27;}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">             }</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The last line means that, for the job to complete successfully, in the appeal_decision table increment, the combination (id, import_date) should be unique, and the id field should be complete.
This is the only script you need to amend at present, but it would be useful to add quality testing to other bits of the process.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="commit-your-changes-in-the-new-branch-and-open-a-pull-request">Commit your changes in the new branch and open a pull request<a class="hash-link" href="#commit-your-changes-in-the-new-branch-and-open-a-pull-request" title="Direct link to heading">​</a></h3><p>Unit tests will run automatically when you push. At the moment, tests are implemented for all bits of the process except from the &#x27;parse table increments&#x27; one.  </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-to-reset-all-refined-tascomi-data">How to reset all refined Tascomi data<a class="hash-link" href="#how-to-reset-all-refined-tascomi-data" title="Direct link to heading">​</a></h2><p>If you suspect a problem in the increments or snapshots, you can delete and recreate them in their respective buckets.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="reset-the-ingested-increments">Reset the ingested increments:<a class="hash-link" href="#reset-the-ingested-increments" title="Direct link to heading">​</a></h3><ul><li>In S3 raw zone &#x27;api<em>response&#x27; bucket, in each table repository, delete the data up to the last date you want to keep. _Do not delete the initial full load!</em></li><li>Run the api_response crawler</li><li>Run the ingestion job</li><li>Run the api_response crawler again.</li></ul><p>As a result you should see in S3 a new partition with today&#x27;s date. It contains all records updated since the last day you kept in the bucket.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="reset-the-parsed-increments">Reset the parsed increments:<a class="hash-link" href="#reset-the-parsed-increments" title="Direct link to heading">​</a></h3><ul><li>In S3 raw zone, empty the &#x27;parsed&#x27; bucket</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value, then save the script:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the parsed bucket crawler</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="reset-the-refined-increments">Reset the refined increments:<a class="hash-link" href="#reset-the-refined-increments" title="Direct link to heading">​</a></h3><ul><li>In S3 refined zone, empty the &#x27;increments&#x27; bucket</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the refined increment crawler</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="reset-the-refined-snapshot">Reset the refined snapshot:<a class="hash-link" href="#reset-the-refined-snapshot" title="Direct link to heading">​</a></h3><ul><li>In S3 refined zone, empty the &#x27;snapshot&#x27; bucket</li><li>Delete all the snapshot tables in the Glue catalogue</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;snapshot_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;snapshot_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the refined snapshot crawler.</li></ul><p>As a resut you should only have today&#x27;s snapshot in the snapshot bucket.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="how-to-rewind-to-a-past-state-and-recreate-the-snapshots-from-there">How to rewind to a past state and recreate the snapshots from there<a class="hash-link" href="#how-to-rewind-to-a-past-state-and-recreate-the-snapshots-from-there" title="Direct link to heading">​</a></h2><p><strong>This method uses the AWS CLI</strong>
Follow these steps if a problem occured at a recent date and you don&#x27;t want to reset the full history of snapshots. You will reset the bookmarks to a date prior to the problem, delete all the snapshots since that date in S3, and run the snapshot job again.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="delete-recent-data-in-s3-and-crawl">Delete recent data in S3 and crawl<a class="hash-link" href="#delete-recent-data-in-s3-and-crawl" title="Direct link to heading">​</a></h3><p>Say something wrong happened on 23/01/2022 and we are the 25th. You need to delete the snapshots dated 20220123, 20220124 and 20220125.
Do this in AWS CLI using:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws s3 rm s3://dataplatform-prod-refined-zone/planning/tascomi/snapshot --recursive --exclude &#x27;*&#x27; --include &#x27;*20220123*&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>and then</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws s3 rm s3://dataplatform-prod-refined-zone/planning/tascomi/snapshot --recursive --exclude &#x27;*&#x27; --include &#x27;*20220124*&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>and then</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws s3 rm s3://dataplatform-prod-refined-zone/planning/tascomi/snapshot --recursive --exclude &#x27;*&#x27; --include &#x27;*20220125*&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If you also want to delete the refined increments, you can go one level up: </p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws s3 rm s3://dataplatform-prod-refined-zone/planning/tascomi/ --recursive --exclude &#x27;*&#x27; --include &#x27;*20220124*&#x27;</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>etc.</p><p>If you have AWS Vault configured with a profile called preprod, the command becomes: </p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws-vault exec preprod -- aws glue reset-job-bookmark --job-name &#x27;prod tascomi_create_daily_snapshot_planning&#x27; --run-id jr_e6d6c7e66b27ff27929b3f46555ecdcd9f9e068675eaafaf231f4d338d04db33</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Don&#x27;t forget to run the refined snapshot crawler so the Glue catalogue sees the recent changes.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="rewind-the-job-bookmark-to-the-last-day-everything-was-fine">Rewind the job bookmark to the last day everything was fine<a class="hash-link" href="#rewind-the-job-bookmark-to-the-last-day-everything-was-fine" title="Direct link to heading">​</a></h3><p>We are using <a href="https://docs.aws.amazon.com/cli/latest/reference/glue/reset-job-bookmark.html" target="_blank" rel="noopener noreferrer">this method</a> and running in the CLI:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">get-job-bookmark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">--job-name &lt;value&gt;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[--run-id &lt;value&gt;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[--cli-input-json | --cli-input-yaml]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[--generate-cli-skeleton &lt;value&gt;]</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You&#x27;ll find the job-name and the run-id of the last successful run in the &#x27;jobs&#x27; section of the Glue console. An example of full command is:</p><div class="codeBlockContainer_MPoW theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-text codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#bfc7d5"><span class="token plain">aws glue reset-job-bookmark --job-name &#x27;prod tascomi_create_daily_snapshot_planning&#x27; --run-id jr_e6d6c7e66b27ff27929b3f46555ecdcd9f9e068675eaafaf231f4d338d04db33</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="extra-steps-needed-depending-on-the-scenario">Extra steps needed depending on the scenario<a class="hash-link" href="#extra-steps-needed-depending-on-the-scenario" title="Direct link to heading">​</a></h3><ul><li>If you&#x27;re going more than 5 days back, the pushdown predicate menas you won&#x27;t be loading any older snapshot. You need to allow a larger daysbuffer in the pushdown predicate before running the job. Save the script.</li><li>If you are going back to a point when one of the snapshots didn&#x27;t exist (because the endpoint had not been used yet), you need to delete this snapshot table in the Glue catalogue before running the job.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="run-the-daily-snapshot-job-and-crawl">Run the daily snapshot job and crawl<a class="hash-link" href="#run-the-daily-snapshot-job-and-crawl" title="Direct link to heading">​</a></h3><p>Today&#x27;s snapshot will be created. There won&#x27;t be any snapshot between this one and the last day everything was fine. Don&#x27;t forget to run the crawler to see the data in Athena.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/Data-Platform-Playbook/tags/playbook">playbook</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/docs/tascomi-ingestion.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/Data-Platform-Playbook/docs/redshift"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Redshift - Creating users, databases and exposing data from Glue</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">VPC Peering Connection between Data Platform and Production APIs AWS accounts</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#details-of-individual-steps" class="table-of-contents__link toc-highlight">Details of individual steps</a><ul><li><a href="#step-1---ingestion" class="table-of-contents__link toc-highlight">Step 1 - Ingestion</a></li><li><a href="#step-2---daily-parsing-of-the-json-increments" class="table-of-contents__link toc-highlight">Step 2 - Daily parsing of the json increments</a></li><li><a href="#step-3---daily-refinement-of-the-parsed-increments" class="table-of-contents__link toc-highlight">Step 3 - Daily refinement of the parsed increments</a></li><li><a href="#step-4---creation-of-the-daily-snapshot" class="table-of-contents__link toc-highlight">Step 4 - Creation of the daily snapshot</a></li><li><a href="#step-5---creation-of-latest-tables-in-the-trusted-zone" class="table-of-contents__link toc-highlight">Step 5 - Creation of latest tables in the Trusted zone</a></li></ul></li><li><a href="#full-workflow-and-scheduling" class="table-of-contents__link toc-highlight">Full workflow and scheduling</a></li><li><a href="#structure-of-the-s3-buckets-and-glue-tables" class="table-of-contents__link toc-highlight">Structure of the S3 buckets and Glue tables</a></li><li><a href="#how-to-add-a-table-to-the-pipeline" class="table-of-contents__link toc-highlight">How to add a table to the pipeline</a><ul><li><a href="#test-the-endpoint" class="table-of-contents__link toc-highlight">Test the endpoint</a></li><li><a href="#create-and-check-out-a-new-branch-in-the-repository" class="table-of-contents__link toc-highlight">Create and check out a new branch in the repository</a></li><li><a href="#add-the-table-to-the-column-type-dictionary" class="table-of-contents__link toc-highlight">Add the table to the column type dictionary</a></li><li><a href="#add-the-table-to-the-terraform-script" class="table-of-contents__link toc-highlight">Add the table to the Terraform script.</a></li><li><a href="#add-data-quality-tests-in-the-relevant-scripts" class="table-of-contents__link toc-highlight">Add data quality tests in the relevant scripts</a></li><li><a href="#commit-your-changes-in-the-new-branch-and-open-a-pull-request" class="table-of-contents__link toc-highlight">Commit your changes in the new branch and open a pull request</a></li></ul></li><li><a href="#how-to-reset-all-refined-tascomi-data" class="table-of-contents__link toc-highlight">How to reset all refined Tascomi data</a><ul><li><a href="#reset-the-ingested-increments" class="table-of-contents__link toc-highlight">Reset the ingested increments:</a></li><li><a href="#reset-the-parsed-increments" class="table-of-contents__link toc-highlight">Reset the parsed increments:</a></li><li><a href="#reset-the-refined-increments" class="table-of-contents__link toc-highlight">Reset the refined increments:</a></li><li><a href="#reset-the-refined-snapshot" class="table-of-contents__link toc-highlight">Reset the refined snapshot:</a></li></ul></li><li><a href="#how-to-rewind-to-a-past-state-and-recreate-the-snapshots-from-there" class="table-of-contents__link toc-highlight">How to rewind to a past state and recreate the snapshots from there</a><ul><li><a href="#delete-recent-data-in-s3-and-crawl" class="table-of-contents__link toc-highlight">Delete recent data in S3 and crawl</a></li><li><a href="#rewind-the-job-bookmark-to-the-last-day-everything-was-fine" class="table-of-contents__link toc-highlight">Rewind the job bookmark to the last day everything was fine</a></li><li><a href="#extra-steps-needed-depending-on-the-scenario" class="table-of-contents__link toc-highlight">Extra steps needed depending on the scenario</a></li><li><a href="#run-the-daily-snapshot-job-and-crawl" class="table-of-contents__link toc-highlight">Run the daily snapshot job and crawl</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Made by HackIT.</div></div></div></footer></div>
<script src="/Data-Platform-Playbook/assets/js/runtime~main.6ed04a66.js"></script>
<script src="/Data-Platform-Playbook/assets/js/main.aa2b627a.js"></script>
</body>
</html>